[2017-10-06 14:04:40,334] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:04:40,366] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:04:40,372] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:04:40,431] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:04:40,455] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:04:40,593] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:04:40,613] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:04:40,622] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:04:40,657] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,663] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,667] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,672] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,676] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,680] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,873] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,894] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,906] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,914] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,920] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,928] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,937] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,946] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:40,979] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:41,009] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:41,033] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:41,060] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:41,117] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:04:41,176] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62303 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:04:41,226] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:04:41,279] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62303 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:04:41,416] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:04:41,427] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:04:41,433] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:04:41,438] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:04:42,055] INFO Accepted socket connection from /127.0.0.1:62313 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:04:42,066] INFO Client attempting to establish new session at /127.0.0.1:62313 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:42,074] INFO Creating new log file: log.b41 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 14:04:42,104] INFO Established session 0x15ef2dc5c8c0000 with negotiated timeout 30000 for client /127.0.0.1:62313 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:42,708] INFO Processed session termination for sessionid: 0x15ef2dc5c8c0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:04:42,727] INFO Closed socket connection for client /127.0.0.1:62313 which had sessionid 0x15ef2dc5c8c0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:04:43,138] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:04:43,443] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:04:43,458] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:04:43,484] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:04:43,497] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,502] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,508] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,513] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,518] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,523] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,698] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,713] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,720] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,724] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,729] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,734] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,738] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,743] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,748] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,760] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:43,800] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:04:43,803] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:43,815] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:43,814] INFO Accepted socket connection from /127.0.0.1:62317 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:04:43,830] INFO Client attempting to establish new session at /127.0.0.1:62317 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:43,844] INFO Established session 0x15ef2dc5c8c0001 with negotiated timeout 6000 for client /127.0.0.1:62317 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:43,847] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2dc5c8c0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:43,862] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:04:44,127] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:04:44,213] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:44,218] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:44,218] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:44,566] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:04:44,720] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:44,757] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:04:44,777] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:44,787] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:04:44,847] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:44,965] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:04:45,033] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:45,039] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:04:45,089] INFO Processed session termination for sessionid: 0x15ef2dc5c8c0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:04:45,124] INFO Closed socket connection for client /127.0.0.1:62317 which had sessionid 0x15ef2dc5c8c0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:04:45,087] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:45,127] INFO EventThread shut down for session: 0x15ef2dc5c8c0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:44,681] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:04:45,123] INFO Session: 0x15ef2dc5c8c0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,188] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:45,204] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:04:45,222] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:04:45,237] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:45,284] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:04:45,321] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:04:45,438] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:04:45,449] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:04:45,483] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:04:45,498] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,506] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,514] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,520] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,526] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,533] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,786] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,836] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,844] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,855] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,861] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,866] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,875] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,881] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,886] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,897] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:04:45,953] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:04:45,957] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:45,971] INFO Accepted socket connection from /127.0.0.1:62320 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:04:45,973] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:45,994] INFO Client attempting to establish new session at /127.0.0.1:62320 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:46,013] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2dc5c8c0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:04:46,046] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:04:46,006] INFO Established session 0x15ef2dc5c8c0002 with negotiated timeout 6000 for client /127.0.0.1:62320 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:46,361] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:04:46,453] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:46,459] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:46,459] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:04:46,786] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:04:46,814] INFO Logs loading complete in 24 ms. (kafka.log.LogManager)
[2017-10-06 14:04:46,918] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 14:04:46,930] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 14:04:47,071] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 14:04:47,082] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 14:04:47,119] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,126] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,126] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,244] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,258] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,272] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:04:47,354] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:04:47,360] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:04:47,392] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:04:47,425] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:15000,blockEndProducerId:15999) by writing to Zk with path version 16 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:04:47,516] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:04:47,524] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:04:47,524] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:04:47,595] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 14:04:47,820] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:04:47,834] INFO Got user-level KeeperException when processing sessionid:0x15ef2dc5c8c0002 type:create cxid:0x62 zxid:0xb47 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:04:47,845] INFO Got user-level KeeperException when processing sessionid:0x15ef2dc5c8c0002 type:create cxid:0x63 zxid:0xb48 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:04:47,873] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:04:47,879] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 14:04:47,897] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:04:47,902] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:04:47,908] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 14:04:48,001] INFO Expiring session 0x15eed8850e60005, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:04:48,006] INFO Processed session termination for sessionid: 0x15eed8850e60005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:04:48,029] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:04:48,041] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:04:49,465] INFO Got user-level KeeperException when processing sessionid:0x15ef2dc5c8c0002 type:delete cxid:0x1c1 zxid:0xb4d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:06:53,476] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:06:53,492] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 14:06:53,581] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 14:06:53,597] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 14:06:53,647] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 14:06:53,661] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:06:53,678] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:06:53,699] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:54,695] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:54,695] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:54,718] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:55,693] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:55,693] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:55,699] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:56,694] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:56,694] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:06:56,706] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 14:06:56,712] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:56,806] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:56,806] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:56,814] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:06:56,826] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 15000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:06:56,833] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 14:06:56,838] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:06:56,844] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:06:56,844] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:06:56,858] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:06:56,865] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:06:56,871] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,006] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,006] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,014] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,011] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,031] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,038] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:06:57,045] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 14:06:57,051] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:06:57,061] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:06:57,066] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,206] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,206] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,216] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,406] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,406] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,410] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,607] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,607] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:06:57,626] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 14:06:57,635] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 14:06:57,659] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 14:06:57,678] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:06:57,684] INFO Processed session termination for sessionid: 0x15ef2dc5c8c0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:06:57,699] INFO Session: 0x15ef2dc5c8c0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:06:57,711] INFO EventThread shut down for session: 0x15ef2dc5c8c0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:06:57,700] INFO Closed socket connection for client /127.0.0.1:62320 which had sessionid 0x15ef2dc5c8c0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:06:57,715] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:10:21,699] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:10:22,172] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:10:22,198] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:10:22,322] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,398] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:10:22,398] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,407] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,413] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,417] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,490] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:10:22,427] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,679] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,700] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,729] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,764] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,813] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,879] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,912] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,920] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,952] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:22,952] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:10:22,966] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:23,010] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:10:23,048] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:10:23,079] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:10:23,087] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:23,091] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:10:23,130] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:10:23,190] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:10:23,228] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:10:23,255] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,268] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,272] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,277] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,286] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,297] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,542] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,560] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,574] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,581] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,587] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,590] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,598] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,604] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,609] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,629] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,632] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,640] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:23,671] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:10:23,896] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:10:23,910] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:10:23,919] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:10:23,928] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:10:24,054] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62358 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:10:24,082] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62358 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:24,092] INFO Creating new log file: log.b4f (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 14:10:24,128] INFO Established session 0x15ef2e1965d0000 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62358 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:24,163] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:24,163] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62359 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:10:24,183] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62359 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:24,206] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef2e1965d0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:24,202] INFO Established session 0x15ef2e1965d0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62359 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:24,227] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:10:24,002] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:10:24,347] INFO Processed session termination for sessionid: 0x15ef2e1965d0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:10:24,361] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62358 which had sessionid 0x15ef2e1965d0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:10:24,462] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:10:24,471] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:10:24,505] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:10:24,519] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,526] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,531] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,541] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,545] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,553] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:10:24,658] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:24,658] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:24,668] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:24,552] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:24,989] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,083] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:10:25,086] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,129] INFO Logs loading complete in 42 ms. (kafka.log.LogManager)
[2017-10-06 14:10:25,128] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,140] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,146] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,153] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,158] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,163] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,169] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,175] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:25,222] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:10:25,225] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:25,236] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:25,236] INFO Accepted socket connection from /127.0.0.1:62366 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:10:25,241] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 14:10:25,256] INFO Client attempting to establish new session at /127.0.0.1:62366 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:25,264] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 14:10:25,269] INFO Established session 0x15ef2e1965d0002 with negotiated timeout 6000 for client /127.0.0.1:62366 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:10:25,273] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2e1965d0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:25,290] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:10:25,400] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 14:10:25,407] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 14:10:25,446] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,454] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,454] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,599] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:10:25,622] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,631] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:10:25,622] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,622] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:10:25,622] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:10:25,724] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:10:25,820] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:10:25,896] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:10:25,924] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:16000,blockEndProducerId:16999) by writing to Zk with path version 17 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:10:26,046] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:26,057] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:10:26,053] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:26,046] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:10:26,070] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:10:26,132] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:10:26,235] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 14:10:26,657] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:10:26,800] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:10:26,808] INFO Got user-level KeeperException when processing sessionid:0x15ef2e1965d0001 type:create cxid:0xe9 zxid:0xb56 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:10:26,847] INFO Got user-level KeeperException when processing sessionid:0x15ef2e1965d0001 type:create cxid:0xea zxid:0xb57 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:10:26,878] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:10:26,888] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 14:10:26,905] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:10:26,922] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:10:26,988] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 14:10:26,969] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,024] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:10:27,037] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,045] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:10:27,095] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,267] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:10:27,312] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:10:27,322] INFO Processed session termination for sessionid: 0x15ef2e1965d0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:10:27,323] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,344] INFO EventThread shut down for session: 0x15ef2e1965d0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:10:27,342] INFO Session: 0x15ef2e1965d0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:10:27,344] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e1965d0002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:10:27,379] INFO Closed socket connection for client /127.0.0.1:62366 which had sessionid 0x15ef2e1965d0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:10:27,387] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,391] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:10:27,424] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:10:27,429] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:10:27,511] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:10:28,110] INFO Got user-level KeeperException when processing sessionid:0x15ef2e1965d0001 type:delete cxid:0x1be zxid:0xb5a txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:14:36,860] INFO Accepted socket connection from /127.0.0.1:62386 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:14:36,867] INFO Client attempting to establish new session at /127.0.0.1:62386 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:36,880] INFO Established session 0x15ef2e1965d0003 with negotiated timeout 30000 for client /127.0.0.1:62386 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:37,335] INFO Processed session termination for sessionid: 0x15ef2e1965d0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:14:37,360] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e1965d0003, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:14:37,384] INFO Closed socket connection for client /127.0.0.1:62386 which had sessionid 0x15ef2e1965d0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:14:37,581] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:14:38,941] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:14:38,953] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:14:38,958] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:14:38,964] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:14:38,970] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:14:39,025] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:14:39,040] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:14:39,086] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,106] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,111] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,116] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,150] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,175] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,660] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,686] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,693] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,720] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,729] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,736] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,747] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,760] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,767] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,791] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,819] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,829] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:39,872] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:14:39,884] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:14:40,388] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:14:40,671] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:14:40,677] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:14:40,707] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:14:40,720] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,725] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,730] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,733] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,739] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,745] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,930] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,954] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,976] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,989] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:40,996] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,009] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,013] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,033] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,039] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,049] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,124] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:14:41,128] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:41,156] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:41,156] INFO Accepted socket connection from /127.0.0.1:62398 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:14:41,188] INFO Client attempting to establish new session at /127.0.0.1:62398 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:41,203] INFO Established session 0x15ef2e1965d0004 with negotiated timeout 6000 for client /127.0.0.1:62398 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:41,209] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2e1965d0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:41,241] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:14:40,865] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:14:41,483] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:14:41,497] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:14:41,555] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:14:41,566] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,575] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,586] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,590] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:14:41,592] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,604] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:41,710] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:41,726] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:41,726] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:41,610] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,131] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:14:42,200] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:14:42,214] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:14:42,188] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,221] INFO Processed session termination for sessionid: 0x15ef2e1965d0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:14:42,267] INFO Session: 0x15ef2e1965d0004 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,254] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,271] INFO EventThread shut down for session: 0x15ef2e1965d0004 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:42,271] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e1965d0004, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:14:42,276] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,309] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:14:42,300] INFO Closed socket connection for client /127.0.0.1:62398 which had sessionid 0x15ef2e1965d0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:14:42,314] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,319] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:14:42,352] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:14:42,331] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,357] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,363] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,369] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,373] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,381] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:42,423] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:14:42,427] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:42,438] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62401 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:14:42,439] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:42,454] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62401 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:42,466] INFO Established session 0x15ef2e1965d0005 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62401 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:14:42,469] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef2e1965d0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:42,490] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:14:42,745] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:14:42,841] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:42,847] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:42,847] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:14:43,142] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:14:43,250] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,271] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:14:43,282] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,286] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:14:43,310] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,361] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:14:43,390] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,393] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:14:43,410] INFO Processed session termination for sessionid: 0x15ef2e1965d0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:14:43,419] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,428] INFO EventThread shut down for session: 0x15ef2e1965d0005 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:14:43,427] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e1965d0005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:14:43,426] INFO Session: 0x15ef2e1965d0005 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:14:43,460] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62401 which had sessionid 0x15ef2e1965d0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:14:43,453] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,477] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:14:43,493] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:14:43,505] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:14:43,531] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:16:22,193] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:16:22,205] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 14:16:22,280] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 14:16:22,305] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 14:16:22,351] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 14:16:22,362] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:16:22,380] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:16:22,400] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:23,262] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:23,263] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:23,274] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:24,263] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:24,263] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:24,287] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:25,267] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:25,267] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:25,286] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 14:16:25,295] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,406] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,406] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,418] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:16:25,434] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 16000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:16:25,445] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 14:16:25,453] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:16:25,465] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:16:25,465] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:16:25,486] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:16:25,496] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:16:25,502] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,607] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,607] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,626] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,807] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,807] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:25,815] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:16:25,836] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 14:16:25,845] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:16:25,858] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:16:25,866] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,007] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,007] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,024] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,207] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,207] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,221] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,407] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,407] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:26,432] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 14:16:26,439] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 14:16:26,470] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 14:16:26,497] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:16:26,508] INFO Processed session termination for sessionid: 0x15ef2e1965d0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:16:26,535] INFO Session: 0x15ef2e1965d0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:26,547] INFO EventThread shut down for session: 0x15ef2e1965d0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:26,550] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:16:26,555] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e1965d0001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:16:26,585] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62359 which had sessionid 0x15ef2e1965d0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:16:42,173] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:16:43,410] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:16:43,422] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:16:43,426] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:16:43,431] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:16:43,435] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:16:43,470] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:16:43,481] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:16:43,509] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,521] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,526] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,532] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,543] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,548] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,855] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,883] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,894] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,902] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,908] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,914] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,922] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,929] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,935] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,956] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,961] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:43,966] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:44,002] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:16:44,230] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:16:44,266] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:16:44,276] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:16:44,295] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:16:44,221] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:16:44,549] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:16:44,559] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:16:44,587] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:16:44,599] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,605] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,611] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,615] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,625] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,632] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,823] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,843] INFO Accepted socket connection from /127.0.0.1:62421 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:16:44,846] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,855] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,860] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,868] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,873] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,870] INFO Client attempting to establish new session at /127.0.0.1:62421 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:44,880] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,893] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,884] INFO Creating new log file: log.b62 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 14:16:44,900] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,907] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:44,928] INFO Established session 0x15ef2e7643d0000 with negotiated timeout 30000 for client /127.0.0.1:62421 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:44,966] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:16:44,969] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:44,983] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:44,982] INFO Accepted socket connection from /127.0.0.1:62424 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:16:45,006] INFO Client attempting to establish new session at /127.0.0.1:62424 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:45,016] INFO Established session 0x15ef2e7643d0001 with negotiated timeout 6000 for client /127.0.0.1:62424 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:45,022] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2e7643d0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:45,039] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:16:45,033] INFO Processed session termination for sessionid: 0x15ef2e7643d0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:16:45,057] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e7643d0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:16:45,075] INFO Closed socket connection for client /127.0.0.1:62421 which had sessionid 0x15ef2e7643d0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:16:45,331] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:16:45,408] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:45,413] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:45,413] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:45,727] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:16:45,846] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:45,874] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:16:45,885] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:45,898] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:16:45,931] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:45,992] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:16:46,027] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:16:46,029] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:46,032] INFO Processed session termination for sessionid: 0x15ef2e7643d0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:16:46,062] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:46,075] INFO EventThread shut down for session: 0x15ef2e7643d0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:46,072] INFO Session: 0x15ef2e7643d0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,072] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e7643d0001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:16:46,098] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:46,123] INFO Closed socket connection for client /127.0.0.1:62424 which had sessionid 0x15ef2e7643d0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:16:46,126] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:16:46,146] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:46,149] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:16:46,186] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:16:46,207] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:16:46,355] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:16:46,655] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:16:46,663] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:16:46,684] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:16:46,692] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,698] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,708] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,711] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,716] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,721] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,865] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,876] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,888] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,891] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,895] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,898] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,903] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,907] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,910] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,918] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:16:46,948] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:16:46,951] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:46,962] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62427 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:16:46,962] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:46,976] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62427 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:46,987] INFO Established session 0x15ef2e7643d0002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62427 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:16:46,990] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef2e7643d0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:16:47,003] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:16:47,266] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:16:47,353] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:47,353] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:47,360] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:16:47,725] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:16:47,749] INFO Logs loading complete in 21 ms. (kafka.log.LogManager)
[2017-10-06 14:16:47,875] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 14:16:47,886] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 14:16:48,006] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 14:16:48,016] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 14:16:48,055] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,064] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,064] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,183] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,195] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,195] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:16:48,208] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:16:48,247] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:16:48,314] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:16:48,328] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:16:48,352] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:16:48,395] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:17000,blockEndProducerId:17999) by writing to Zk with path version 18 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:16:48,510] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:16:48,521] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:16:48,566] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:16:48,623] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 14:16:49,007] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:16:49,028] INFO Got user-level KeeperException when processing sessionid:0x15ef2e7643d0002 type:create cxid:0xc1 zxid:0xb6a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:16:49,045] INFO Got user-level KeeperException when processing sessionid:0x15ef2e7643d0002 type:create cxid:0xc2 zxid:0xb6b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:16:49,066] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:16:49,073] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 14:16:49,099] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:16:49,106] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:16:49,115] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 14:16:50,119] INFO Got user-level KeeperException when processing sessionid:0x15ef2e7643d0002 type:delete cxid:0x1be zxid:0xb6d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:26:40,660] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62558 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:26:40,690] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62558 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:40,722] INFO Established session 0x15ef2e7643d0003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62558 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:41,298] INFO Processed session termination for sessionid: 0x15ef2e7643d0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:26:41,321] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e7643d0003, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:26:41,350] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62558 which had sessionid 0x15ef2e7643d0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:26:41,544] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:26:42,040] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:26:42,053] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:26:42,062] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:26:42,070] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:26:42,074] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:26:42,119] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:26:42,128] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:26:42,162] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,176] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,181] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,188] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,192] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,197] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,398] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,421] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,430] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,439] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,453] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,458] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,465] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,473] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,479] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,512] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,516] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,520] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:42,562] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:26:42,569] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:26:44,794] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:26:45,069] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:26:45,075] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:26:45,107] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:26:45,118] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,123] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,130] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,134] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,139] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,144] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,329] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,352] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,359] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,367] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,373] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,379] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,393] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,399] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,416] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,424] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,489] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:26:45,495] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:45,511] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:45,510] INFO Accepted socket connection from /127.0.0.1:62569 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:26:45,539] INFO Client attempting to establish new session at /127.0.0.1:62569 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:45,558] INFO Established session 0x15ef2e7643d0004 with negotiated timeout 6000 for client /127.0.0.1:62569 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:45,561] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef2e7643d0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:45,588] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:26:45,302] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:26:45,858] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:26:45,881] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:26:45,933] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:26:45,944] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,956] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,963] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,971] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:45,977] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:26:45,977] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,099] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:46,118] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:46,118] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:45,990] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,534] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:26:46,607] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:26:46,628] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:26:46,592] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,638] INFO Processed session termination for sessionid: 0x15ef2e7643d0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:26:46,644] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,663] INFO Session: 0x15ef2e7643d0004 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,669] INFO EventThread shut down for session: 0x15ef2e7643d0004 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:46,656] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,686] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:26:46,689] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,697] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:26:46,721] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:26:46,703] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,668] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e7643d0004, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:26:46,729] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,736] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,733] INFO Closed socket connection for client /127.0.0.1:62569 which had sessionid 0x15ef2e7643d0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:26:46,744] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,756] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,762] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:46,805] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:26:46,817] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:46,827] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62572 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:26:46,829] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:46,847] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62572 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:46,858] INFO Established session 0x15ef2e7643d0005 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62572 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:26:46,861] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef2e7643d0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:46,881] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:26:47,200] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:26:47,279] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:47,287] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:47,287] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:47,631] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:26:47,774] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:47,800] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:26:47,812] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:47,817] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:26:47,851] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:47,919] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:26:47,953] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:26:47,958] INFO Processed session termination for sessionid: 0x15ef2e7643d0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:26:47,955] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:47,976] INFO EventThread shut down for session: 0x15ef2e7643d0005 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:47,975] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef2e7643d0005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:26:47,974] INFO Session: 0x15ef2e7643d0005 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:48,011] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62572 which had sessionid 0x15ef2e7643d0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:26:48,011] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:48,042] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:26:48,057] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:26:48,062] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:26:48,096] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:26:48,327] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:26:54,667] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:26:54,683] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 14:26:54,846] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 14:26:54,870] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 14:26:54,942] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 14:26:54,956] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:26:54,979] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:26:54,997] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:55,837] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:55,838] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:55,853] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,837] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,837] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,854] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,907] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,907] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:26:56,926] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 14:26:56,934] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,024] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,024] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,040] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:26:57,053] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 17000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:26:57,068] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 14:26:57,075] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:26:57,087] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:26:57,087] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:26:57,108] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:26:57,118] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:26:57,126] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,213] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,213] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,221] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,236] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,242] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,264] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:26:57,274] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 14:26:57,282] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:26:57,297] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:26:57,303] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,436] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,436] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,456] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,625] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,625] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,638] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,815] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,815] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:26:57,829] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 14:26:57,837] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 14:26:57,859] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 14:26:57,878] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:26:57,888] INFO Processed session termination for sessionid: 0x15ef2e7643d0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:26:57,902] INFO Session: 0x15ef2e7643d0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:26:57,910] INFO EventThread shut down for session: 0x15ef2e7643d0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:26:57,907] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62427 which had sessionid 0x15ef2e7643d0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:26:57,913] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:47:44,398] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:47:44,753] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:47:44,765] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:47:44,784] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:47:44,799] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:47:44,819] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:47:44,876] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:47:44,918] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:47:44,988] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:44,999] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,029] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,045] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,058] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,066] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,293] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,309] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,324] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,330] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,338] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,351] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,379] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,388] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,395] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,417] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,420] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,423] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:45,459] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:47:45,492] INFO Accepted socket connection from /127.0.0.1:62653 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:47:45,514] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:47:45,528] INFO Closed socket connection for client /127.0.0.1:62653 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:47:45,758] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:47:45,769] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:47:45,791] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:47:45,805] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:47:46,764] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:47:46,964] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62660 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:47:46,981] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62660 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:46,988] INFO Creating new log file: log.b75 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 14:47:47,010] INFO Established session 0x15ef303cbca0000 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62660 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:47,066] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:47:47,074] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:47:47,100] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:47:47,101] INFO Processed session termination for sessionid: 0x15ef303cbca0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:47:47,112] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,120] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,125] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,132] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,139] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,123] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:47:47,160] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62660 which had sessionid 0x15ef303cbca0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:47:47,148] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,338] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,352] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,364] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,368] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,372] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,377] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,380] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,386] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,390] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,398] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:47,433] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:47:47,437] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:47,445] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62663 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:47:47,446] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:47,462] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62663 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:47,472] INFO Established session 0x15ef303cbca0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62663 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:47,476] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef303cbca0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:47,491] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:47:47,745] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:47:47,834] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:47,839] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:47,839] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:48,149] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:47:48,168] INFO Logs loading complete in 17 ms. (kafka.log.LogManager)
[2017-10-06 14:47:48,267] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 14:47:48,281] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 14:47:48,423] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 14:47:48,442] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 14:47:48,254] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:47:48,494] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,500] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,521] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,613] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,634] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:47:48,672] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:47:48,723] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:47:48,729] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:47:48,757] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,766] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:18000,blockEndProducerId:18999) by writing to Zk with path version 19 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:47:48,766] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:47:48,829] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:47:48,836] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:47:48,872] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:47:48,839] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:47:48,926] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 14:47:48,929] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:47:48,996] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:47:49,142] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:47:49,153] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,216] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:47:49,190] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,228] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,236] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,226] INFO Got user-level KeeperException when processing sessionid:0x15ef303cbca0001 type:create cxid:0xbd zxid:0xb7b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:47:49,243] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,244] INFO Got user-level KeeperException when processing sessionid:0x15ef303cbca0001 type:create cxid:0xbe zxid:0xb7c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:47:49,274] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:47:49,282] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 14:47:49,302] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:47:49,307] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 14:47:49,318] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 14:47:49,251] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,597] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,618] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,625] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,646] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,659] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,663] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,690] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,701] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,715] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,720] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:49,779] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:47:49,783] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:49,816] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62676 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:47:49,816] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:49,837] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62676 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:49,847] INFO Established session 0x15ef303cbca0002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62676 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:47:49,849] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef303cbca0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:49,863] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:47:50,362] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:47:50,406] INFO Got user-level KeeperException when processing sessionid:0x15ef303cbca0001 type:delete cxid:0x1be zxid:0xb7f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:47:50,594] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:50,610] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:50,610] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:47:51,369] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:47:51,497] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,534] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:47:51,551] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:47:51,551] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,617] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:47:51,647] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,649] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:47:51,667] INFO Processed session termination for sessionid: 0x15ef303cbca0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:47:51,675] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,680] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:47:51,681] INFO EventThread shut down for session: 0x15ef303cbca0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:47:51,679] INFO Session: 0x15ef303cbca0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:47:51,707] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62676 which had sessionid 0x15ef303cbca0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:47:51,718] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,735] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:47:51,748] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:47:51,762] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:47:51,785] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:15,386] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62684 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:15,393] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62684 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:15,410] INFO Established session 0x15ef303cbca0003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62684 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:15,874] INFO Processed session termination for sessionid: 0x15ef303cbca0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:15,886] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0003, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:15,904] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62684 which had sessionid 0x15ef303cbca0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:17,452] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:48:17,796] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:48:17,802] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:48:17,831] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:17,841] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,848] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,859] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,869] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,875] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,151] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,180] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,189] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,210] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,220] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,224] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,230] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,239] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,257] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,267] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:17,930] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:48:18,324] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:18,327] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:18,338] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:18,338] INFO Accepted socket connection from /127.0.0.1:62689 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:18,382] INFO Client attempting to establish new session at /127.0.0.1:62689 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:18,399] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef303cbca0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:18,409] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:18,397] INFO Established session 0x15ef303cbca0004 with negotiated timeout 6000 for client /127.0.0.1:62689 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:18,598] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:48:18,659] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:48:18,724] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:18,743] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:48:18,729] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,757] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,764] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,774] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,781] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:18,842] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:18,857] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:18,857] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:19,232] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:48:19,296] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:18,809] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,317] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:19,376] INFO Processed session termination for sessionid: 0x15ef303cbca0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:19,373] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,402] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,400] INFO Session: 0x15ef303cbca0004 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,415] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,403] INFO EventThread shut down for session: 0x15ef303cbca0004 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:19,425] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,435] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,436] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:48:19,402] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0004, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:19,453] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,454] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:48:19,461] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,470] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,475] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,484] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:19,455] INFO Closed socket connection for client /127.0.0.1:62689 which had sessionid 0x15ef303cbca0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:19,527] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:19,531] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:19,541] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:19,540] INFO Accepted socket connection from /127.0.0.1:62692 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:19,555] INFO Client attempting to establish new session at /127.0.0.1:62692 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:19,604] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef303cbca0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:19,599] INFO Established session 0x15ef303cbca0005 with negotiated timeout 6000 for client /127.0.0.1:62692 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:19,565] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:19,614] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:19,925] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:48:20,032] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:20,076] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:20,082] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:20,377] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:48:20,397] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:48:20,460] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:20,513] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:20,526] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:20,542] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,562] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:48:20,571] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:48:20,585] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,635] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:48:20,668] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:48:20,589] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:20,724] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:20,645] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,744] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:20,709] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:20,759] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:20,767] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:20,702] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:48:20,774] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:20,776] INFO Processed session termination for sessionid: 0x15ef303cbca0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:20,790] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:20,770] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,802] INFO EventThread shut down for session: 0x15ef303cbca0005 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:20,799] INFO Session: 0x15ef303cbca0005 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:20,803] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:20,829] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,858] INFO Closed socket connection for client /127.0.0.1:62692 which had sessionid 0x15ef303cbca0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:20,848] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:48:20,898] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,899] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:48:20,940] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:20,973] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:20,804] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,122] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,139] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,149] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,155] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,161] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,164] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,171] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,179] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,186] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,203] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,206] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,211] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:21,240] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:21,247] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:48:28,844] INFO Accepted socket connection from /127.0.0.1:62702 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:28,864] INFO Client attempting to establish new session at /127.0.0.1:62702 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:28,876] INFO Established session 0x15ef303cbca0006 with negotiated timeout 30000 for client /127.0.0.1:62702 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:29,300] INFO Processed session termination for sessionid: 0x15ef303cbca0006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:29,316] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:29,339] INFO Closed socket connection for client /127.0.0.1:62702 which had sessionid 0x15ef303cbca0006 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:30,035] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:48:31,373] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:48:31,388] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:31,395] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:31,401] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:48:31,409] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:48:31,155] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:48:31,472] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:48:31,515] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:48:31,544] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,551] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,556] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,561] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,567] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,616] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:48:31,639] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:48:31,708] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:31,710] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:31,735] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:31,749] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:31,762] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:31,774] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:31,573] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,805] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,834] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,849] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,868] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,880] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,890] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,898] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,918] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,930] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,962] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,970] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:31,988] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:32,045] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:31,785] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,102] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,057] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:48:32,140] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,160] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,163] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,170] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,174] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,177] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,183] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,191] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,197] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:32,239] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:32,243] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:32,253] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62712 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:32,254] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:32,270] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62712 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:32,284] INFO Established session 0x15ef303cbca0007 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62712 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:32,284] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef303cbca0007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:32,303] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:32,634] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:48:32,721] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:32,721] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:32,727] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:33,077] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:48:33,124] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:33,143] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:33,149] INFO Processed session termination for sessionid: 0x15ef303cbca0007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:33,163] INFO Session: 0x15ef303cbca0007 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:33,165] INFO EventThread shut down for session: 0x15ef303cbca0007 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:33,163] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62712 which had sessionid 0x15ef303cbca0007 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:33,181] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:48:33,185] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:48:33,203] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:33,713] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:48:33,951] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:48:33,958] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:48:33,983] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:33,993] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:33,997] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,003] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,009] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,013] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,017] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,192] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,207] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,217] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,221] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,228] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,232] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,236] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,241] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,248] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,255] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:34,297] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:34,300] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:34,313] INFO Accepted socket connection from /127.0.0.1:62716 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:48:34,315] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:34,335] INFO Client attempting to establish new session at /127.0.0.1:62716 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:34,348] INFO Established session 0x15ef303cbca0008 with negotiated timeout 6000 for client /127.0.0.1:62716 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:48:34,352] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef303cbca0008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:34,369] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:48:34,641] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:48:34,733] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:34,740] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:34,740] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:48:35,105] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:48:35,247] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,274] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:48:35,291] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,303] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:35,345] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,415] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:48:35,451] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:48:35,456] INFO Processed session termination for sessionid: 0x15ef303cbca0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:48:35,454] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,480] INFO EventThread shut down for session: 0x15ef303cbca0008 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:48:35,478] INFO Session: 0x15ef303cbca0008 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:48:35,478] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca0008, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:48:35,522] INFO Closed socket connection for client /127.0.0.1:62716 which had sessionid 0x15ef303cbca0008 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:48:35,500] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,529] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:48:35,561] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:48:35,573] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:48:35,600] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:50:22,260] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62726 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:50:22,272] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62726 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:22,284] INFO Established session 0x15ef303cbca0009 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62726 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:22,747] INFO Processed session termination for sessionid: 0x15ef303cbca0009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:50:22,787] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62726 which had sessionid 0x15ef303cbca0009 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:50:23,948] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:50:23,993] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:50:23,998] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:50:24,004] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:50:24,011] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:50:24,056] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:50:24,066] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:50:24,098] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,108] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,115] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,119] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,124] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,135] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,438] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,480] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,486] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,499] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,550] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,567] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,577] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,583] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,619] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,663] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,667] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,676] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:24,714] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:50:24,725] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:50:24,999] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:50:25,429] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:50:25,439] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:50:25,495] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,505] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,514] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,518] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,513] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:50:25,526] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,541] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,755] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,771] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,781] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,784] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,791] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,795] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,803] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,810] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,818] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,824] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:25,870] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:50:25,878] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:50:25,889] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:50:25,888] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62736 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:50:25,903] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62736 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:25,919] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef303cbca000a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:50:25,933] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:50:25,916] INFO Established session 0x15ef303cbca000a with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62736 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:50:26,221] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:50:26,318] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:50:26,331] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:50:26,332] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:50:26,664] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:50:26,764] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:50:26,793] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:50:26,798] INFO Processed session termination for sessionid: 0x15ef303cbca000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:50:26,815] INFO Session: 0x15ef303cbca000a closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:50:26,818] INFO EventThread shut down for session: 0x15ef303cbca000a (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:50:26,837] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:50:26,816] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca000a, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:50:26,843] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:50:26,846] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62736 which had sessionid 0x15ef303cbca000a (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:50:26,893] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:50:27,239] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:51:39,540] INFO Accepted socket connection from /127.0.0.1:62741 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:51:39,550] INFO Client attempting to establish new session at /127.0.0.1:62741 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:39,560] INFO Established session 0x15ef303cbca000b with negotiated timeout 30000 for client /127.0.0.1:62741 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:39,993] INFO Processed session termination for sessionid: 0x15ef303cbca000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:51:40,018] INFO Closed socket connection for client /127.0.0.1:62741 which had sessionid 0x15ef303cbca000b (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:51:40,919] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:51:41,287] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:51:41,299] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:51:41,366] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,372] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,377] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,372] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:51:41,389] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,400] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,406] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,595] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,619] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,621] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:51:41,627] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,633] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,634] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:51:41,641] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,645] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:51:41,649] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,650] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:51:41,655] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,663] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:51:41,668] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,678] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,688] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:41,705] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:51:41,715] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:51:41,733] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:51:41,743] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,746] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:41,752] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,758] INFO Accepted socket connection from /127.0.0.1:62746 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:51:41,759] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:41,767] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,777] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,780] INFO Client attempting to establish new session at /127.0.0.1:62746 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,785] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,794] INFO Established session 0x15ef303cbca000c with negotiated timeout 6000 for client /127.0.0.1:62746 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:41,798] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef303cbca000c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:41,815] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:51:42,231] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:51:41,792] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,260] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,286] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,347] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,394] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:42,394] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:42,394] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:42,395] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,453] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,494] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,572] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,689] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,765] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,781] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:51:42,795] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:51:42,815] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,850] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,874] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:42,988] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:51:43,021] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:51:42,970] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:51:43,032] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:51:43,035] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:51:43,084] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 14:51:43,127] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:51:43,193] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:51:43,200] INFO Processed session termination for sessionid: 0x15ef303cbca000c (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:51:43,214] INFO Closed socket connection for client /127.0.0.1:62746 which had sessionid 0x15ef303cbca000c (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:51:43,208] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:51:43,217] INFO EventThread shut down for session: 0x15ef303cbca000c (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:43,214] INFO Session: 0x15ef303cbca000c closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:43,265] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:51:43,272] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:51:43,290] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:51:43,334] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:51:44,786] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:51:45,106] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:51:45,114] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:51:45,143] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:51:45,153] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,162] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,168] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,172] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,180] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,186] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,385] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,404] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,411] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,415] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,424] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,428] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,432] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,439] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,445] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,453] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:45,493] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:51:45,497] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:45,510] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62756 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:51:45,511] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:45,529] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62756 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:45,544] INFO Established session 0x15ef303cbca000d with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62756 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:51:45,547] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef303cbca000d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:45,562] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:51:45,837] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:51:45,924] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:45,931] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:45,931] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:51:46,272] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:51:46,333] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:51:46,351] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:51:46,365] INFO Processed session termination for sessionid: 0x15ef303cbca000d (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:51:46,388] INFO Session: 0x15ef303cbca000d closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:51:46,391] INFO EventThread shut down for session: 0x15ef303cbca000d (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:51:46,417] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:51:46,424] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:51:46,391] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef303cbca000d, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:51:46,452] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62756 which had sessionid 0x15ef303cbca000d (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:51:46,471] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:52:01,592] WARN Session 0x15ef303cbca0001 for server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:01,758] INFO zookeeper state changed (Disconnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:52:02,260] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:03,273] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:04,863] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:05,873] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:06,046] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:07,059] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:07,922] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:52:07,937] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 14:52:08,452] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:09,464] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:09,591] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:52:09,925] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:10,942] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:12,746] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:13,762] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:14,256] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:15,263] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:17,202] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:18,217] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:18,755] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:19,769] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:21,215] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:22,226] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:22,948] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:23,965] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:25,483] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:26,489] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:27,577] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:28,590] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:29,850] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:30,870] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:31,775] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:32,788] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:33,999] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:35,016] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:35,828] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:36,836] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:38,704] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:39,717] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:40,769] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:41,781] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:43,374] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:44,386] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:44,868] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:45,880] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:47,714] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:48,725] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:49,664] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:50,676] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:52,522] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:53,532] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:54,288] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:55,298] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:56,813] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:57,819] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:52:58,449] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:52:59,460] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:53:01,290] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:02,304] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:53:02,487] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:03,501] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:53:05,649] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:06,660] WARN Session 0x15ef303cbca0001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 14:53:07,309] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:45,895] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:53:46,099] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:53:46,164] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:53:46,185] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:53:46,233] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 14:53:46,293] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:53:46,302] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:53:46,264] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 14:53:46,336] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 14:53:46,356] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 14:53:46,382] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,389] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,411] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,430] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,413] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,401] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:53:46,435] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,439] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,469] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,467] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,479] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,645] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:53:46,479] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,752] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,780] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,819] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,535] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,868] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,878] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,911] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,874] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,935] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,952] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,959] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,968] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:46,995] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:46,995] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,005] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:47,015] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,028] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,040] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,082] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,098] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:53:47,105] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,130] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:47,144] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,149] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,154] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,195] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:53:47,420] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:53:47,426] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:53:47,435] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:53:47,444] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 14:53:47,585] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62812 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:53:47,603] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62812 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,609] INFO Creating new log file: log.b97 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 14:53:47,644] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:47,644] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62813 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:53:47,647] INFO Established session 0x15ef309505e0000 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62812 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,669] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62813 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,712] INFO Established session 0x15ef309505e0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62813 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:47,715] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef309505e0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:47,748] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:53:47,574] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 14:53:48,195] INFO starting (kafka.server.KafkaServer)
[2017-10-06 14:53:48,224] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 14:53:48,243] INFO Processed session termination for sessionid: 0x15ef309505e0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:48,257] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62812 which had sessionid 0x15ef309505e0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:53:48,302] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:53:48,306] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,323] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,328] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,334] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,341] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,347] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:53:48,468] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:48,485] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:48,485] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:48,348] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,609] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,641] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,648] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,660] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,665] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,683] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,692] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,762] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,908] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,924] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:53:48,928] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:48,992] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:53:49,003] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:49,014] INFO Accepted socket connection from /127.0.0.1:62820 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 14:53:49,015] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:49,030] INFO Client attempting to establish new session at /127.0.0.1:62820 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:49,042] INFO Established session 0x15ef309505e0002 with negotiated timeout 6000 for client /127.0.0.1:62820 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:49,045] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef309505e0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:49,061] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 14:53:49,110] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:53:49,139] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 14:53:49,152] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 14:53:49,159] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:53:49,231] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:53:49,267] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:53:49,272] INFO Processed session termination for sessionid: 0x15ef309505e0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:49,268] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:53:49,291] INFO Session: 0x15ef309505e0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:49,292] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62813 which had sessionid 0x15ef309505e0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:53:49,294] INFO EventThread shut down for session: 0x15ef309505e0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:49,323] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:53:49,311] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:53:49,328] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:53:49,369] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 14:53:49,407] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:53:49,487] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 14:53:49,551] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:49,559] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:49,559] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:50,006] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 14:53:50,032] INFO Logs loading complete in 23 ms. (kafka.log.LogManager)
[2017-10-06 14:53:50,159] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 14:53:50,172] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 14:53:50,294] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 14:53:50,305] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 14:53:50,342] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,350] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,350] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,457] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,468] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,484] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:50,582] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:53:50,589] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:53:50,609] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 14:53:50,645] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:19000,blockEndProducerId:19999) by writing to Zk with path version 20 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:53:50,737] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:53:50,747] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:53:50,747] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:53:50,820] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 14:53:51,067] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:53:51,083] INFO Got user-level KeeperException when processing sessionid:0x15ef309505e0002 type:create cxid:0x62 zxid:0xb9d txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:51,092] INFO Got user-level KeeperException when processing sessionid:0x15ef309505e0002 type:create cxid:0x63 zxid:0xb9e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:51,111] INFO Got user-level KeeperException when processing sessionid:0x15ef309505e0002 type:create cxid:0x64 zxid:0xb9f txntype:-1 reqpath:n/a Error Path:/brokers/ids/1 Error:KeeperErrorCode = NodeExists for /brokers/ids/1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:51,138] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 14:53:51,145] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/1. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:420)
	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:403)
	at kafka.server.KafkaHealthcheck.register(KafkaHealthcheck.scala:71)
	at kafka.server.KafkaHealthcheck.startup(KafkaHealthcheck.scala:50)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:280)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 14:53:51,186] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:53:51,195] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 14:53:51,221] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 14:53:51,227] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:53:51,294] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 14:53:51,307] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,558] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,558] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,565] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,563] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,582] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:51,590] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:52,570] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:52,570] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 14:53:52,589] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 14:53:52,602] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,672] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,672] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,693] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:53:52,721] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 19000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 14:53:52,732] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 14:53:52,743] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:53:52,752] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:53:52,752] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 14:53:52,773] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 14:53:52,785] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:53:52,791] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,888] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,888] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:52,906] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,104] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,104] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,109] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 14:53:53,121] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 14:53:53,127] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:53:53,137] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 14:53:53,142] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,170] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,170] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,175] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,359] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,359] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,369] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,565] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,565] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 14:53:53,584] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 14:53:53,588] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 14:53:53,614] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 14:53:53,632] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 14:53:53,637] INFO Processed session termination for sessionid: 0x15ef309505e0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 14:53:53,649] INFO Session: 0x15ef309505e0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 14:53:53,649] INFO Closed socket connection for client /127.0.0.1:62820 which had sessionid 0x15ef309505e0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 14:53:53,652] INFO EventThread shut down for session: 0x15ef309505e0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 14:53:53,670] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 14:53:53,674] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 14:53:53,687] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 14:53:54,001] INFO Expiring session 0x15ef303cbca0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 14:53:54,008] INFO Processed session termination for sessionid: 0x15ef303cbca0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:02,350] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:17:06,780] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:06,898] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,032] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,124] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,192] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:17:07,326] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:07,481] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:17:07,604] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,621] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:07,677] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,736] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,769] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,777] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,804] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,825] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:07,862] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,883] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:17:07,938] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:08,003] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:17:08,085] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,099] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,109] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,119] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,128] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:07,900] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,272] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,346] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,375] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,398] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,432] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,462] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,138] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,486] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,487] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,524] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,528] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,556] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,583] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,596] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,613] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,614] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,637] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,683] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,755] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:08,726] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,791] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,845] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,916] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:08,986] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63189 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:09,033] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:09,048] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:09,090] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:09,077] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:17:09,127] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:09,169] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:17:09,096] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63189 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:09,196] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:17:09,222] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:17:09,229] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:09,280] INFO Accepted socket connection from /127.0.0.1:63190 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:09,301] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:09,307] INFO Closed socket connection for client /127.0.0.1:63190 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:09,287] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 17:17:10,691] INFO Accepted socket connection from /127.0.0.1:63204 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:10,806] INFO Client attempting to establish new session at /127.0.0.1:63204 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:10,918] INFO Creating new log file: log.ba2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 17:17:10,919] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63206 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:10,935] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:17:11,187] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63206 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:11,070] INFO Established session 0x15ef38c91190000 with negotiated timeout 30000 for client /127.0.0.1:63204 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:11,443] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:17:11,500] INFO Established session 0x15ef38c91190001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:63206 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:12,076] INFO Processed session termination for sessionid: 0x15ef38c91190001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:12,177] INFO Processed session termination for sessionid: 0x15ef38c91190000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:12,184] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:12,354] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:12,449] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63206 which had sessionid 0x15ef38c91190001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:12,697] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:12,968] INFO Closed socket connection for client /127.0.0.1:63204 which had sessionid 0x15ef38c91190000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:13,061] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:13,127] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:13,309] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:13,320] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,335] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,375] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,413] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,434] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,159] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:13,482] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,780] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,846] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,886] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,897] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,937] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,977] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:13,979] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:13,997] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,032] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,032] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:14,043] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,088] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,150] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,216] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:14,218] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,203] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:14,276] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:14,284] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,333] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:14,331] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,332] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63210 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:14,356] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,370] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63210 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:14,416] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef38c91190002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:14,445] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:14,413] INFO Established session 0x15ef38c91190002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63210 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:13,952] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:14,404] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:14,345] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:14,942] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,021] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:15,021] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,053] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:15,053] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,108] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,181] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:15,175] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,195] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,165] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:15,157] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,201] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,212] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,220] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,209] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,227] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:15,261] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,292] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,329] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,368] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,370] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,385] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:15,370] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:15,385] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:15,428] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:15,412] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,462] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,491] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,544] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,490] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:15,618] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:15,680] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63213 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:15,682] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:15,230] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,209] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:15,753] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63213 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:15,806] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef38c91190003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:15,755] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,799] INFO Established session 0x15ef38c91190003 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63213 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:15,850] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,849] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:16,023] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,181] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,216] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,243] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,269] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:17:16,263] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,293] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:15,328] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:16,316] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,346] INFO Logs loading complete in 71 ms. (kafka.log.LogManager)
[2017-10-06 17:17:15,563] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,374] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,369] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,406] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,435] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,464] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,503] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:16,521] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,596] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:16,626] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:16,608] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,634] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:17:16,654] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:17:16,622] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,642] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,674] INFO Accepted socket connection from /127.0.0.1:63216 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:16,672] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,672] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:16,674] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,714] INFO Client attempting to establish new session at /127.0.0.1:63216 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:16,705] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,727] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,735] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef38c91190004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,789] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:16,730] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,732] INFO Established session 0x15ef38c91190004 with negotiated timeout 6000 for client /127.0.0.1:63216 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:16,765] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:16,806] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,852] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:16,905] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,915] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,914] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63225 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:16,938] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63225 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:16,950] INFO Established session 0x15ef38c91190005 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63225 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:16,900] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:16,953] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef38c91190005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:16,970] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 17:17:16,974] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:17,044] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:17:16,967] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:17,071] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:17,102] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:17,184] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,185] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,185] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,104] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:17,104] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:17,838] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:17,855] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,808] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:17:17,751] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:17,855] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,855] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:17,984] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:17:18,015] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:17:17,949] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:17:17,120] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,056] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:17:18,045] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,066] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:17:18,077] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,102] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,113] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:20000,blockEndProducerId:20999) by writing to Zk with path version 21 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:17:18,153] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,242] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:17:18,229] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,283] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:17:18,324] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,408] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:17:18,400] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,402] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:18,554] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:17:18,425] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:18,532] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,403] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:18,562] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:18,743] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 17:17:18,567] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:18,940] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:18,402] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:18,567] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:19,170] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:19,041] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:19,282] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:17:19,234] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:113)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
	at scala.collection.TraversableLike.map(TraversableLike.scala:234)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:227)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:109)
	at kafka.log.LogManager.<init>(LogManager.scala:70)
	at kafka.log.LogManager$.apply(LogManager.scala:610)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:215)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:17:19,493] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:19,572] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:19,573] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:18,759] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:19,689] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:17:19,705] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:19,560] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:19,727] INFO Got user-level KeeperException when processing sessionid:0x15ef38c91190002 type:create cxid:0xdf zxid:0xbad txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:19,712] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:19,737] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:19,750] INFO Got user-level KeeperException when processing sessionid:0x15ef38c91190002 type:create cxid:0xe0 zxid:0xbae txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:19,791] INFO Processed session termination for sessionid: 0x15ef38c91190005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:19,722] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:19,769] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:19,793] INFO Accepted socket connection from /127.0.0.1:63232 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:19,804] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:17:19,794] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:19,814] INFO Session: 0x15ef38c91190005 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:19,828] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:17:19,816] INFO EventThread shut down for session: 0x15ef38c91190005 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:19,862] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:17:19,809] INFO Processed session termination for sessionid: 0x15ef38c91190004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:19,870] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:17:19,872] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:17:19,911] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:17:19,875] INFO Session: 0x15ef38c91190004 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:19,928] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 17:17:19,869] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:19,879] INFO EventThread shut down for session: 0x15ef38c91190004 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:19,946] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:19,952] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:17:19,972] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:17:19,824] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:20,007] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63225 which had sessionid 0x15ef38c91190005 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:20,014] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:20,041] INFO Client attempting to establish new session at /127.0.0.1:63232 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:20,054] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190004, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:20,061] INFO Established session 0x15ef38c91190006 with negotiated timeout 6000 for client /127.0.0.1:63232 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:20,021] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:20,072] INFO Closed socket connection for client /127.0.0.1:63216 which had sessionid 0x15ef38c91190004 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:20,064] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef38c91190006, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:20,112] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:20,095] INFO Processed session termination for sessionid: 0x15ef38c91190003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:20,066] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:20,141] INFO EventThread shut down for session: 0x15ef38c91190003 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:20,135] INFO Session: 0x15ef38c91190003 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:20,136] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190003, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:20,192] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63213 which had sessionid 0x15ef38c91190003 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:20,186] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:20,191] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:17:20,348] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:17:20,289] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\clusterdb-topic2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:20,659] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:20,679] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:21,011] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:21,013] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:21,012] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:21,574] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:17:21,664] INFO Got user-level KeeperException when processing sessionid:0x15ef38c91190002 type:delete cxid:0x1be zxid:0xbb4 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:21,759] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:21,867] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 17:17:21,968] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:21,879] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:22,349] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:22,414] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:22,422] INFO Processed session termination for sessionid: 0x15ef38c91190006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:22,426] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:22,437] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:22,439] INFO EventThread shut down for session: 0x15ef38c91190006 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:22,435] INFO Session: 0x15ef38c91190006 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:22,479] INFO Closed socket connection for client /127.0.0.1:63232 which had sessionid 0x15ef38c91190006 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:22,485] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:22,508] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:17:22,569] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:22,575] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:17:22,626] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:22,667] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:24,857] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:24,868] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:24,874] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:24,879] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:17:24,885] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:17:24,934] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:17:24,955] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:17:24,984] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:24,997] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,003] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,010] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,015] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,024] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,253] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,280] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,290] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,299] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,309] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,315] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,322] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,349] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,359] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,386] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,392] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,407] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,451] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:25,460] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 17:17:25,784] INFO Accepted socket connection from /127.0.0.1:63245 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:25,790] INFO Client attempting to establish new session at /127.0.0.1:63245 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,799] INFO Established session 0x15ef38c91190007 with negotiated timeout 30000 for client /127.0.0.1:63245 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:25,871] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:17:26,285] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:17:26,295] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:17:26,308] INFO Processed session termination for sessionid: 0x15ef38c91190007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:26,332] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:26,321] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38c91190007, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:26,349] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,349] INFO Closed socket connection for client /127.0.0.1:63245 which had sessionid 0x15ef38c91190007 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:26,360] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,374] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,378] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,387] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,391] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,585] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,602] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,610] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,614] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,619] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,624] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,628] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,632] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,640] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,648] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:26,700] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:26,703] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:26,713] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:26,712] INFO Accepted socket connection from /127.0.0.1:63248 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:17:26,730] INFO Client attempting to establish new session at /127.0.0.1:63248 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:26,743] INFO Established session 0x15ef38c91190008 with negotiated timeout 6000 for client /127.0.0.1:63248 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:17:26,745] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef38c91190008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:26,761] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:17:27,006] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:17:27,075] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:27,081] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:27,081] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:27,390] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:17:27,508] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,527] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 17:17:27,549] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,551] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:17:27,588] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,645] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:27,673] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:27,679] INFO Processed session termination for sessionid: 0x15ef38c91190008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:27,674] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,696] INFO Closed socket connection for client /127.0.0.1:63248 which had sessionid 0x15ef38c91190008 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:27,698] INFO EventThread shut down for session: 0x15ef38c91190008 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:27,694] INFO Session: 0x15ef38c91190008 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:27,714] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,731] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:17:27,749] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:17:27,752] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:17:27,779] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:34,389] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:17:34,398] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:17:34,454] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 17:17:34,465] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:17:34,497] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:17:34,509] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:17:34,525] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:17:34,540] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:34,893] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:34,893] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:34,900] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:35,894] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:35,894] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:35,908] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:36,895] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:36,895] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:17:36,900] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:17:36,912] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,083] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,083] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,103] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:17:37,111] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 20000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:17:37,122] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:17:37,129] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:17:37,138] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:17:37,138] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:17:37,156] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:17:37,169] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:17:37,177] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,369] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,369] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,383] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,481] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,481] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,493] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:17:37,501] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:17:37,509] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:17:37,524] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:17:37,530] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,653] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,653] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,660] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,682] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,682] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,690] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,885] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,885] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:17:37,902] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:17:37,911] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:17:37,945] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:17:37,970] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:17:37,980] INFO Processed session termination for sessionid: 0x15ef38c91190002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:17:37,994] INFO Session: 0x15ef38c91190002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:17:37,995] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63210 which had sessionid 0x15ef38c91190002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:17:38,011] INFO EventThread shut down for session: 0x15ef38c91190002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:17:38,014] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:20:42,271] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:20:42,283] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:20:42,290] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:20:42,295] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:20:42,299] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:20:42,338] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:20:42,348] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:20:42,373] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,390] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,408] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,416] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,421] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,428] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,854] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:42,923] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,004] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,093] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,155] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,183] FATAL  (kafka.Kafka$)
java.io.FileNotFoundException: ..\..\config\server2.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:428)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:41)
	at kafka.Kafka$.main(Kafka.scala:57)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:20:43,186] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,259] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,283] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,335] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,422] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,456] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,476] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:43,520] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:20:43,787] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:20:43,796] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:20:43,800] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:20:43,807] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:20:44,352] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:20:44,334] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:20:44,873] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:20:44,880] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:20:44,909] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:20:44,920] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,921] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:20:44,927] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,934] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:20:44,938] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,943] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,950] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,973] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:20:44,986] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,999] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,012] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,022] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,032] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:44,956] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,302] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,335] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,348] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,359] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,368] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,373] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,381] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,388] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,401] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,418] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,050] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,456] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,476] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:20:45,481] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,480] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,503] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,495] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,514] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,504] INFO Accepted socket connection from /127.0.0.1:63263 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:20:45,520] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,532] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,542] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,544] INFO Client attempting to establish new session at /127.0.0.1:63263 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:45,550] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,559] INFO Creating new log file: log.bbb (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 17:20:45,559] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,579] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:45,589] INFO Established session 0x15ef38fd73f0000 with negotiated timeout 6000 for client /127.0.0.1:63263 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:45,596] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef38fd73f0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,616] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:20:45,646] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:20:45,660] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,673] INFO Accepted socket connection from /127.0.0.1:63266 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:20:45,674] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,702] INFO Client attempting to establish new session at /127.0.0.1:63266 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:45,716] INFO Established session 0x15ef38fd73f0001 with negotiated timeout 6000 for client /127.0.0.1:63266 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:20:45,719] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef38fd73f0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:45,740] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:20:45,991] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:20:46,097] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,104] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,104] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,164] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:20:46,531] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:20:46,555] INFO Logs loading complete in 21 ms. (kafka.log.LogManager)
[2017-10-06 17:20:46,690] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:20:46,668] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,697] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,707] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:20:46,669] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:20:46,840] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 17:20:46,861] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:20:47,018] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,018] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,018] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,150] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,197] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:20:47,215] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,241] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:20:47,215] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:20:47,281] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:20:47,299] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:20:47,357] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:21000,blockEndProducerId:21999) by writing to Zk with path version 22 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:20:47,411] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:20:47,510] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:20:47,523] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:20:47,583] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:20:47,595] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:20:47,577] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:20:47,939] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:20:47,952] INFO Got user-level KeeperException when processing sessionid:0x15ef38fd73f0000 type:create cxid:0xb4 zxid:0xbc0 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:20:47,973] INFO Got user-level KeeperException when processing sessionid:0x15ef38fd73f0000 type:create cxid:0xb5 zxid:0xbc1 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:20:47,998] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:20:48,004] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:20:48,022] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:20:48,029] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:20:48,035] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 17:20:48,128] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,188] ERROR There was an error in one of the threads during logs loading: java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.
 (kafka.log.LogManager)
[2017-10-06 17:20:48,201] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,240] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.nio.file.FileSystemException: \tmp\kafka-logs3\cluster-1-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:318)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
	at kafka.log.Log.loadSegmentFiles(Log.scala:279)
	at kafka.log.Log.loadSegments(Log.scala:383)
	at kafka.log.Log.<init>(Log.scala:186)
	at kafka.log.Log$.apply(Log.scala:1610)
	at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:20:48,307] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster-3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,450] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:20:48,575] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:20:48,603] INFO Processed session termination for sessionid: 0x15ef38fd73f0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:20:48,561] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster1-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,621] INFO EventThread shut down for session: 0x15ef38fd73f0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:20:48,617] INFO Session: 0x15ef38fd73f0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:20:48,620] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef38fd73f0001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:20:48,655] INFO Closed socket connection for client /127.0.0.1:63266 which had sessionid 0x15ef38fd73f0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:20:48,638] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster2-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,665] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:20:48,689] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:20:48,753] WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index) has non-zero size but the last offset is 0 which is no larger than the base offset 0.}. deleting C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.timeindex, C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.index, and C:\tmp\kafka-logs3\cluster3-0\00000000000000000000.txnindex and rebuilding index... (kafka.log.Log)
[2017-10-06 17:20:48,816] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:20:49,206] INFO Got user-level KeeperException when processing sessionid:0x15ef38fd73f0000 type:delete cxid:0x1be zxid:0xbc4 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:21:16,034] WARN Session 0x15ef38fd73f0000 for server 127.0.0.1/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:21:16,193] INFO zookeeper state changed (Disconnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:21:16,636] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:21:17,660] WARN Session 0x15ef38fd73f0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:21:19,004] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:21:19,736] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:21:19,744] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:21:20,013] WARN Session 0x15ef38fd73f0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:21:20,131] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:21:20,293] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:21:21,300] WARN Session 0x15ef38fd73f0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:26:05,175] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:26:05,196] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:26:05,202] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:26:05,207] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:26:05,213] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:26:05,254] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:26:05,308] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:26:05,364] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,381] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,413] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,431] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,440] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,454] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,929] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:05,955] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,005] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,053] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,143] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,153] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,208] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,250] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,289] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,331] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,370] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,384] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:06,471] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:26:06,811] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:26:06,827] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:26:06,870] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:26:06,906] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:26:07,224] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:26:07,571] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:26:07,591] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:26:07,642] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:26:07,648] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:07,663] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:07,672] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:07,686] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:07,700] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:07,611] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:26:07,715] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,039] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,071] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,077] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,084] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,103] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,113] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,129] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,137] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,147] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,164] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,205] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:26:08,238] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:26:08,277] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:08,293] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:08,308] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:08,308] INFO Accepted socket connection from /127.0.0.1:63306 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:26:08,328] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:26:08,333] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,352] INFO Client attempting to establish new session at /127.0.0.1:63306 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:08,368] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,370] INFO Creating new log file: log.bc5 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 17:26:08,386] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,398] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,413] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef394c58e0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:08,418] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,410] INFO Established session 0x15ef394c58e0000 with negotiated timeout 6000 for client /127.0.0.1:63306 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:08,445] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:08,112] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:26:08,741] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:26:08,772] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:26:08,453] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,856] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,862] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:26:08,871] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,846] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,885] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,890] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,892] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,907] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,907] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,910] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:26:08,915] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,927] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,930] WARN No meta.properties file under dir C:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:26:08,942] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,952] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,961] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,968] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:08,984] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,056] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:09,059] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:09,052] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:09,085] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,071] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:09,102] INFO Accepted socket connection from /127.0.0.1:63309 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:26:09,103] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,130] INFO Client attempting to establish new session at /127.0.0.1:63309 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:09,150] INFO Established session 0x15ef394c58e0001 with negotiated timeout 6000 for client /127.0.0.1:63309 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:09,153] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef394c58e0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,174] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:08,918] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,318] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,417] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,546] INFO Log directory 'C:\tmp\kafka-logs2' not found, creating it. (kafka.log.LogManager)
[2017-10-06 17:26:09,537] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,587] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,605] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,619] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:26:09,619] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,629] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,636] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,643] INFO Logs loading complete in 19 ms. (kafka.log.LogManager)
[2017-10-06 17:26:09,645] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,663] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:09,719] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:26:09,723] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:09,732] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:26:09,733] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,748] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,747] INFO Accepted socket connection from /127.0.0.1:63312 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:26:09,771] INFO Client attempting to establish new session at /127.0.0.1:63312 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:09,787] INFO Established session 0x15ef394c58e0002 with negotiated timeout 6000 for client /127.0.0.1:63312 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:09,790] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef394c58e0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:09,820] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:26:09,845] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:26:09,879] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:26:09,885] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:09,886] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:09,885] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:10,043] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2017-10-06 17:26:10,124] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:26:10,349] INFO Log directory 'C:\tmp\kafka-logs' not found, creating it. (kafka.log.LogManager)
[2017-10-06 17:26:10,356] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,356] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,387] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:26:10,357] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,429] INFO Logs loading complete in 31 ms. (kafka.log.LogManager)
[2017-10-06 17:26:10,402] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:26:10,447] WARN No meta.properties file under dir C:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:26:10,520] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,522] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,520] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:10,698] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:10,708] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:10,732] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:10,762] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:22000,blockEndProducerId:22999) by writing to Zk with path version 23 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:26:10,732] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:10,732] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:10,732] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:10,807] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:26:10,828] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:26:10,965] INFO [Transaction Coordinator 2]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:11,036] INFO [Transaction Coordinator 2]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:11,088] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:11,128] INFO Log directory 'C:\tmp\kafka-logs1' not found, creating it. (kafka.log.LogManager)
[2017-10-06 17:26:11,211] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:26:11,235] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:26:11,236] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2017-10-06 17:26:11,251] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:26:11,288] INFO Logs loading complete in 47 ms. (kafka.log.LogManager)
[2017-10-06 17:26:11,339] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,339] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,339] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,488] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:11,503] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0000 type:create cxid:0x62 zxid:0xbc9 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:11,523] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0000 type:create cxid:0x63 zxid:0xbca txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:11,581] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:26:11,527] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,593] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,606] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:11,592] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:11,616] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:26:11,734] WARN No meta.properties file under dir C:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:26:11,696] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:26:11,805] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:11,820] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:11,850] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:26:11,869] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 25 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:11,866] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:26:11,921] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2017-10-06 17:26:11,909] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:23000,blockEndProducerId:23999) by writing to Zk with path version 24 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:26:11,969] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 17:26:11,980] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:26:11,992] INFO [Transaction Coordinator 0]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:12,000] INFO [Transaction Coordinator 0]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:12,007] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:12,038] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,038] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,038] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,089] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:26:12,245] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,246] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,357] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:12,245] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:12,380] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:12,375] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0001 type:create cxid:0x62 zxid:0xbcd txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:12,391] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:12,388] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0001 type:create cxid:0x63 zxid:0xbce txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:12,402] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:12,430] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:12,447] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:26:12,458] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:26:12,453] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:24000,blockEndProducerId:24999) by writing to Zk with path version 25 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:26:12,509] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:26:12,516] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:26:12,522] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2017-10-06 17:26:12,540] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:12,547] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:12,547] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:12,602] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:26:12,813] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:12,823] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0002 type:create cxid:0x62 zxid:0xbd1 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:12,832] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0002 type:create cxid:0x63 zxid:0xbd2 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:12,843] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0002 type:create cxid:0x64 zxid:0xbd3 txntype:-1 reqpath:n/a Error Path:/brokers/ids/1 Error:KeeperErrorCode = NodeExists for /brokers/ids/1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:12,870] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:12,880] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/1. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:420)
	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:403)
	at kafka.server.KafkaHealthcheck.register(KafkaHealthcheck.scala:71)
	at kafka.server.KafkaHealthcheck.startup(KafkaHealthcheck.scala:50)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:280)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:65)
	at kafka.Kafka.main(Kafka.scala)
[2017-10-06 17:26:12,911] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:26:12,936] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:26:12,960] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:26:12,964] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:26:13,038] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:26:13,049] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:13,816] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:13,816] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:13,844] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:14,817] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:14,837] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:14,818] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:15,001] INFO Expiring session 0x15ef38fd73f0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:26:15,010] INFO Processed session termination for sessionid: 0x15ef38fd73f0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:15,044] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,080] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,046] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,064] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,173] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0001 type:create cxid:0x6b zxid:0xbd7 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:15,194] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0002 type:create cxid:0x6c zxid:0xbd8 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:15,224] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,224] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:26:15,819] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:15,819] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:26:15,830] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:26:15,846] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,023] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,023] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,039] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:16,106] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 24000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:26:16,220] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:26:16,308] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:16,406] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:16,406] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:26:16,530] INFO Got user-level KeeperException when processing sessionid:0x15ef394c58e0000 type:delete cxid:0x11a zxid:0xbd9 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:16,635] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:26:16,721] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:16,731] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,761] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,765] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,782] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,962] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,962] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,972] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:26:16,998] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:26:17,005] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:26:17,019] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:26:17,025] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:16,946] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,db1-0,__consumer_offsets-30,clusterdb-topic2-0,cluster-3-0,__consumer_offsets-8,__consumer_offsets-21,clusterdb-topic1-0,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,cluster1-0,cluster-2-0,filter-0,clusterdb2-0,__consumer_offsets-25,__consumer_offsets-35,test3-0,demo2-0,__consumer_offsets-41,__consumer_offsets-33,clusterdb-topic5-0,__consumer_offsets-23,__consumer_offsets-49,test-topic3-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,demo5-0,__consumer_offsets-31,clusterdb-topic6-0,__consumer_offsets-36,__consumer_offsets-42,cluster-1-0,__consumer_offsets-3,__consumer_offsets-18,clusterdb1-0,test1-0,cluster3-0,__consumer_offsets-37,demo-0,clusterdb-topic7-0,__consumer_offsets-15,__consumer_offsets-24,db2-0,db-0,clusterdb-topic4-0,demo3-0,test-topic2-0,__consumer_offsets-38,clusterdb3-0,__consumer_offsets-17,__consumer_offsets-48,kafkalogger-0,__consumer_offsets-19,__consumer_offsets-11,cluster2-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,db3-0,test-topic-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,clusterdb-topic3-0,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,test-topic4-0,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,test2-0,__consumer_offsets-32,kafkalogger2-0,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:26:17,152] INFO Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,172] INFO Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2017-10-06 17:26:17,163] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,189] INFO Created log for partition [__consumer_offsets,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,163] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,243] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,235] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2017-10-06 17:26:17,253] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,265] INFO Partition [__consumer_offsets,0] on broker 0: __consumer_offsets-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,303] INFO Loading producer state from offset 0 for partition __consumer_offsets-29 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,309] INFO Completed load of log __consumer_offsets-29 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:26:17,314] INFO Created log for partition [__consumer_offsets,29] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,344] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2017-10-06 17:26:17,349] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,353] INFO Partition [__consumer_offsets,29] on broker 0: __consumer_offsets-29 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,364] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,364] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,377] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,385] INFO Loading producer state from offset 0 for partition __consumer_offsets-48 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,393] INFO Completed load of log __consumer_offsets-48 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:17,400] INFO Created log for partition [__consumer_offsets,48] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,424] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2017-10-06 17:26:17,431] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,436] INFO Partition [__consumer_offsets,48] on broker 0: __consumer_offsets-48 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,465] INFO Loading producer state from offset 0 for partition cluster-2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,472] INFO Completed load of log cluster-2-0 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:26:17,477] INFO Created log for partition [cluster-2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,502] INFO Partition [cluster-2,0] on broker 0: No checkpointed highwatermark is found for partition cluster-2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:17,517] INFO Replica loaded for partition cluster-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,523] INFO Partition [cluster-2,0] on broker 0: cluster-2-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,560] INFO Loading producer state from offset 0 for partition __consumer_offsets-10 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,564] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,573] INFO Completed load of log __consumer_offsets-10 with 1 log segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2017-10-06 17:26:17,564] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:26:17,587] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:26:17,609] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:26:17,592] INFO Created log for partition [__consumer_offsets,10] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,659] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:26:17,660] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2017-10-06 17:26:17,672] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:26:17,674] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,683] INFO Processed session termination for sessionid: 0x15ef394c58e0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:26:17,688] INFO Partition [__consumer_offsets,10] on broker 0: __consumer_offsets-10 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,703] INFO Session: 0x15ef394c58e0002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:26:17,708] INFO EventThread shut down for session: 0x15ef394c58e0002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:26:17,725] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:26:17,733] FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
[2017-10-06 17:26:17,707] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef394c58e0002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:26:17,750] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:26:17,748] INFO Closed socket connection for client /127.0.0.1:63312 which had sessionid 0x15ef394c58e0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:26:17,798] INFO Loading producer state from offset 0 for partition __consumer_offsets-45 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,809] INFO Completed load of log __consumer_offsets-45 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:17,820] INFO Created log for partition [__consumer_offsets,45] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,862] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2017-10-06 17:26:17,876] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,884] INFO Partition [__consumer_offsets,45] on broker 0: __consumer_offsets-45 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:17,923] INFO Loading producer state from offset 0 for partition cluster2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:17,934] INFO Completed load of log cluster2-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2017-10-06 17:26:17,942] INFO Created log for partition [cluster2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:17,984] INFO Partition [cluster2,0] on broker 0: No checkpointed highwatermark is found for partition cluster2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:17,992] INFO Replica loaded for partition cluster2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:17,999] INFO Partition [cluster2,0] on broker 0: cluster2-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,036] INFO Loading producer state from offset 0 for partition __consumer_offsets-26 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,047] INFO Completed load of log __consumer_offsets-26 with 1 log segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2017-10-06 17:26:18,058] INFO Created log for partition [__consumer_offsets,26] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,106] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2017-10-06 17:26:18,117] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,123] INFO Partition [__consumer_offsets,26] on broker 0: __consumer_offsets-26 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,159] INFO Loading producer state from offset 0 for partition demo3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,169] INFO Completed load of log demo3-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:18,178] INFO Created log for partition [demo3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,228] INFO Partition [demo3,0] on broker 0: No checkpointed highwatermark is found for partition demo3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:18,238] INFO Replica loaded for partition demo3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,244] INFO Partition [demo3,0] on broker 0: demo3-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,282] INFO Loading producer state from offset 0 for partition test1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,292] INFO Completed load of log test1-0 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:18,299] INFO Created log for partition [test1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,340] INFO Partition [test1,0] on broker 0: No checkpointed highwatermark is found for partition test1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:18,354] INFO Replica loaded for partition test1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,361] INFO Partition [test1,0] on broker 0: test1-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,398] INFO Loading producer state from offset 0 for partition __consumer_offsets-7 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,410] INFO Completed load of log __consumer_offsets-7 with 1 log segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2017-10-06 17:26:18,419] INFO Created log for partition [__consumer_offsets,7] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,459] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2017-10-06 17:26:18,473] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,479] INFO Partition [__consumer_offsets,7] on broker 0: __consumer_offsets-7 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,517] INFO Loading producer state from offset 0 for partition __consumer_offsets-42 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,529] INFO Completed load of log __consumer_offsets-42 with 1 log segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2017-10-06 17:26:18,539] INFO Created log for partition [__consumer_offsets,42] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,579] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2017-10-06 17:26:18,593] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,600] INFO Partition [__consumer_offsets,42] on broker 0: __consumer_offsets-42 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,634] INFO Loading producer state from offset 0 for partition db-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,643] INFO Completed load of log db-0 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:18,649] INFO Created log for partition [db,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,682] INFO Partition [db,0] on broker 0: No checkpointed highwatermark is found for partition db-0 (kafka.cluster.Partition)
[2017-10-06 17:26:18,688] INFO Replica loaded for partition db-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,693] INFO Partition [db,0] on broker 0: db-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,728] INFO Loading producer state from offset 0 for partition __consumer_offsets-4 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,738] INFO Completed load of log __consumer_offsets-4 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:18,743] INFO Created log for partition [__consumer_offsets,4] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,780] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2017-10-06 17:26:18,792] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,799] INFO Partition [__consumer_offsets,4] on broker 0: __consumer_offsets-4 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,832] INFO Loading producer state from offset 0 for partition __consumer_offsets-23 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,842] INFO Completed load of log __consumer_offsets-23 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:18,848] INFO Created log for partition [__consumer_offsets,23] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,880] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2017-10-06 17:26:18,892] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:18,899] INFO Partition [__consumer_offsets,23] on broker 0: __consumer_offsets-23 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:18,931] INFO Loading producer state from offset 0 for partition clusterdb-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:18,943] INFO Completed load of log clusterdb-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:18,951] INFO Created log for partition [clusterdb-topic2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:18,988] INFO Partition [clusterdb-topic2,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:18,998] INFO Replica loaded for partition clusterdb-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,003] INFO Partition [clusterdb-topic2,0] on broker 0: clusterdb-topic2-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,033] INFO Loading producer state from offset 0 for partition clusterdb1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,043] INFO Completed load of log clusterdb1-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:19,049] INFO Created log for partition [clusterdb1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,083] INFO Partition [clusterdb1,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:19,095] INFO Replica loaded for partition clusterdb1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,106] INFO Partition [clusterdb1,0] on broker 0: clusterdb1-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,132] INFO Loading producer state from offset 0 for partition kafkalogger2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,141] INFO Completed load of log kafkalogger2-0 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:19,147] INFO Created log for partition [kafkalogger2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,182] INFO Partition [kafkalogger2,0] on broker 0: No checkpointed highwatermark is found for partition kafkalogger2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:19,189] INFO Replica loaded for partition kafkalogger2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,196] INFO Partition [kafkalogger2,0] on broker 0: kafkalogger2-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,230] INFO Loading producer state from offset 0 for partition __consumer_offsets-1 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,239] INFO Completed load of log __consumer_offsets-1 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:19,246] INFO Created log for partition [__consumer_offsets,1] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,281] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,293] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,299] INFO Partition [__consumer_offsets,1] on broker 0: __consumer_offsets-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,326] INFO Loading producer state from offset 0 for partition __consumer_offsets-20 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,334] INFO Completed load of log __consumer_offsets-20 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:26:19,340] INFO Created log for partition [__consumer_offsets,20] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,374] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2017-10-06 17:26:19,387] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,391] INFO Partition [__consumer_offsets,20] on broker 0: __consumer_offsets-20 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,423] INFO Loading producer state from offset 0 for partition __consumer_offsets-39 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,431] INFO Completed load of log __consumer_offsets-39 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:19,437] INFO Created log for partition [__consumer_offsets,39] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,468] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2017-10-06 17:26:19,477] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,483] INFO Partition [__consumer_offsets,39] on broker 0: __consumer_offsets-39 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,512] INFO Loading producer state from offset 0 for partition clusterdb-topic5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,521] INFO Completed load of log clusterdb-topic5-0 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:19,526] INFO Created log for partition [clusterdb-topic5,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,556] INFO Partition [clusterdb-topic5,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic5-0 (kafka.cluster.Partition)
[2017-10-06 17:26:19,572] INFO Replica loaded for partition clusterdb-topic5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,577] INFO Partition [clusterdb-topic5,0] on broker 0: clusterdb-topic5-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,609] INFO Loading producer state from offset 0 for partition __consumer_offsets-17 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,618] INFO Completed load of log __consumer_offsets-17 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:19,623] INFO Created log for partition [__consumer_offsets,17] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,653] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2017-10-06 17:26:19,667] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,672] INFO Partition [__consumer_offsets,17] on broker 0: __consumer_offsets-17 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,711] INFO Loading producer state from offset 0 for partition __consumer_offsets-36 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,721] INFO Completed load of log __consumer_offsets-36 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:19,727] INFO Created log for partition [__consumer_offsets,36] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,758] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2017-10-06 17:26:19,770] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,776] INFO Partition [__consumer_offsets,36] on broker 0: __consumer_offsets-36 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,804] INFO Loading producer state from offset 0 for partition test-topic-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,813] INFO Completed load of log test-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:19,819] INFO Created log for partition [test-topic,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,849] INFO Partition [test-topic,0] on broker 0: No checkpointed highwatermark is found for partition test-topic-0 (kafka.cluster.Partition)
[2017-10-06 17:26:19,855] INFO Replica loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,861] INFO Partition [test-topic,0] on broker 0: test-topic-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:19,887] INFO Loading producer state from offset 0 for partition demo2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:19,897] INFO Completed load of log demo2-0 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:19,903] INFO Created log for partition [demo2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:19,950] INFO Partition [demo2,0] on broker 0: No checkpointed highwatermark is found for partition demo2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:19,962] INFO Replica loaded for partition demo2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:19,971] INFO Partition [demo2,0] on broker 0: demo2-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,019] INFO Loading producer state from offset 0 for partition __consumer_offsets-14 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,028] INFO Completed load of log __consumer_offsets-14 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2017-10-06 17:26:20,042] INFO Created log for partition [__consumer_offsets,14] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,097] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2017-10-06 17:26:20,107] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,118] INFO Partition [__consumer_offsets,14] on broker 0: __consumer_offsets-14 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,157] INFO Loading producer state from offset 0 for partition test-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,166] INFO Completed load of log test-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:20,174] INFO Created log for partition [test-topic3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,210] INFO Partition [test-topic3,0] on broker 0: No checkpointed highwatermark is found for partition test-topic3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:20,219] INFO Replica loaded for partition test-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,225] INFO Partition [test-topic3,0] on broker 0: test-topic3-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,257] INFO Loading producer state from offset 0 for partition demo5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,265] INFO Completed load of log demo5-0 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:20,270] INFO Created log for partition [demo5,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,298] INFO Partition [demo5,0] on broker 0: No checkpointed highwatermark is found for partition demo5-0 (kafka.cluster.Partition)
[2017-10-06 17:26:20,310] INFO Replica loaded for partition demo5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,315] INFO Partition [demo5,0] on broker 0: demo5-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,345] INFO Loading producer state from offset 0 for partition test3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,352] INFO Completed load of log test3-0 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:20,358] INFO Created log for partition [test3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,386] INFO Partition [test3,0] on broker 0: No checkpointed highwatermark is found for partition test3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:20,392] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,399] INFO Partition [test3,0] on broker 0: test3-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,424] INFO Loading producer state from offset 0 for partition db1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,434] INFO Completed load of log db1-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:20,442] INFO Created log for partition [db1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,476] INFO Partition [db1,0] on broker 0: No checkpointed highwatermark is found for partition db1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:20,491] INFO Replica loaded for partition db1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,497] INFO Partition [db1,0] on broker 0: db1-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,530] INFO Loading producer state from offset 0 for partition __consumer_offsets-33 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,539] INFO Completed load of log __consumer_offsets-33 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:20,545] INFO Created log for partition [__consumer_offsets,33] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,586] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2017-10-06 17:26:20,592] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,599] INFO Partition [__consumer_offsets,33] on broker 0: __consumer_offsets-33 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,625] INFO Loading producer state from offset 0 for partition __consumer_offsets-49 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,634] INFO Completed load of log __consumer_offsets-49 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:20,640] INFO Created log for partition [__consumer_offsets,49] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,666] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2017-10-06 17:26:20,673] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,680] INFO Partition [__consumer_offsets,49] on broker 0: __consumer_offsets-49 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,710] INFO Loading producer state from offset 0 for partition cluster-1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,717] INFO Completed load of log cluster-1-0 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:26:20,721] INFO Created log for partition [cluster-1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,747] INFO Partition [cluster-1,0] on broker 0: No checkpointed highwatermark is found for partition cluster-1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:20,753] INFO Replica loaded for partition cluster-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,761] INFO Partition [cluster-1,0] on broker 0: cluster-1-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,793] INFO Loading producer state from offset 0 for partition __consumer_offsets-11 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,801] INFO Completed load of log __consumer_offsets-11 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:20,807] INFO Created log for partition [__consumer_offsets,11] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,837] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2017-10-06 17:26:20,854] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,859] INFO Partition [__consumer_offsets,11] on broker 0: __consumer_offsets-11 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,899] INFO Loading producer state from offset 0 for partition __consumer_offsets-30 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:20,907] INFO Completed load of log __consumer_offsets-30 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:20,912] INFO Created log for partition [__consumer_offsets,30] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:20,940] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2017-10-06 17:26:20,957] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:20,961] INFO Partition [__consumer_offsets,30] on broker 0: __consumer_offsets-30 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:20,992] INFO Loading producer state from offset 0 for partition __consumer_offsets-46 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,002] INFO Completed load of log __consumer_offsets-46 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:21,010] INFO Created log for partition [__consumer_offsets,46] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,044] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2017-10-06 17:26:21,060] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,067] INFO Partition [__consumer_offsets,46] on broker 0: __consumer_offsets-46 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,103] INFO Loading producer state from offset 0 for partition __consumer_offsets-27 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,115] INFO Completed load of log __consumer_offsets-27 with 1 log segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2017-10-06 17:26:21,123] INFO Created log for partition [__consumer_offsets,27] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,161] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2017-10-06 17:26:21,179] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,184] INFO Partition [__consumer_offsets,27] on broker 0: __consumer_offsets-27 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,217] INFO Loading producer state from offset 0 for partition clusterdb-topic7-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,225] INFO Completed load of log clusterdb-topic7-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:21,231] INFO Created log for partition [clusterdb-topic7,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,268] INFO Partition [clusterdb-topic7,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic7-0 (kafka.cluster.Partition)
[2017-10-06 17:26:21,276] INFO Replica loaded for partition clusterdb-topic7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,283] INFO Partition [clusterdb-topic7,0] on broker 0: clusterdb-topic7-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,310] INFO Loading producer state from offset 0 for partition cluster1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,320] INFO Completed load of log cluster1-0 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:21,325] INFO Created log for partition [cluster1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,365] INFO Partition [cluster1,0] on broker 0: No checkpointed highwatermark is found for partition cluster1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:21,382] INFO Replica loaded for partition cluster1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,387] INFO Partition [cluster1,0] on broker 0: cluster1-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,421] INFO Loading producer state from offset 0 for partition __consumer_offsets-8 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,430] INFO Completed load of log __consumer_offsets-8 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:21,437] INFO Created log for partition [__consumer_offsets,8] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,472] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2017-10-06 17:26:21,491] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,498] INFO Partition [__consumer_offsets,8] on broker 0: __consumer_offsets-8 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,532] INFO Loading producer state from offset 0 for partition clusterdb3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,541] INFO Completed load of log clusterdb3-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:21,548] INFO Created log for partition [clusterdb3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,586] INFO Partition [clusterdb3,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:21,604] INFO Replica loaded for partition clusterdb3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,610] INFO Partition [clusterdb3,0] on broker 0: clusterdb3-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,642] INFO Loading producer state from offset 0 for partition __consumer_offsets-24 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,651] INFO Completed load of log __consumer_offsets-24 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:21,659] INFO Created log for partition [__consumer_offsets,24] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,702] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2017-10-06 17:26:21,723] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,730] INFO Partition [__consumer_offsets,24] on broker 0: __consumer_offsets-24 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,768] INFO Loading producer state from offset 0 for partition __consumer_offsets-43 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,779] INFO Completed load of log __consumer_offsets-43 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:21,785] INFO Created log for partition [__consumer_offsets,43] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,822] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2017-10-06 17:26:21,839] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,844] INFO Partition [__consumer_offsets,43] on broker 0: __consumer_offsets-43 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,881] INFO Loading producer state from offset 0 for partition __consumer_offsets-5 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,889] INFO Completed load of log __consumer_offsets-5 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:21,898] INFO Created log for partition [__consumer_offsets,5] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:21,932] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2017-10-06 17:26:21,954] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:21,960] INFO Partition [__consumer_offsets,5] on broker 0: __consumer_offsets-5 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:21,988] INFO Loading producer state from offset 0 for partition clusterdb-topic1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:21,998] INFO Completed load of log clusterdb-topic1-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:22,006] INFO Created log for partition [clusterdb-topic1,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,042] INFO Partition [clusterdb-topic1,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic1-0 (kafka.cluster.Partition)
[2017-10-06 17:26:22,059] INFO Replica loaded for partition clusterdb-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,064] INFO Partition [clusterdb-topic1,0] on broker 0: clusterdb-topic1-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,096] INFO Loading producer state from offset 0 for partition clusterdb-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,105] INFO Completed load of log clusterdb-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:22,112] INFO Created log for partition [clusterdb-topic4,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,145] INFO Partition [clusterdb-topic4,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic4-0 (kafka.cluster.Partition)
[2017-10-06 17:26:22,152] INFO Replica loaded for partition clusterdb-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,160] INFO Partition [clusterdb-topic4,0] on broker 0: clusterdb-topic4-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,197] INFO Loading producer state from offset 0 for partition demo-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,206] INFO Completed load of log demo-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:22,215] INFO Created log for partition [demo,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,248] INFO Partition [demo,0] on broker 0: No checkpointed highwatermark is found for partition demo-0 (kafka.cluster.Partition)
[2017-10-06 17:26:22,257] INFO Replica loaded for partition demo-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,264] INFO Partition [demo,0] on broker 0: demo-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,297] INFO Loading producer state from offset 0 for partition __consumer_offsets-21 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,305] INFO Completed load of log __consumer_offsets-21 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:22,311] INFO Created log for partition [__consumer_offsets,21] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,349] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2017-10-06 17:26:22,357] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,364] INFO Partition [__consumer_offsets,21] on broker 0: __consumer_offsets-21 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,393] INFO Loading producer state from offset 0 for partition __consumer_offsets-40 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,403] INFO Completed load of log __consumer_offsets-40 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:22,409] INFO Created log for partition [__consumer_offsets,40] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,446] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2017-10-06 17:26:22,454] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,462] INFO Partition [__consumer_offsets,40] on broker 0: __consumer_offsets-40 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,504] INFO Loading producer state from offset 0 for partition __consumer_offsets-2 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,515] INFO Completed load of log __consumer_offsets-2 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:22,522] INFO Created log for partition [__consumer_offsets,2] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,556] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2017-10-06 17:26:22,574] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,580] INFO Partition [__consumer_offsets,2] on broker 0: __consumer_offsets-2 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,618] INFO Loading producer state from offset 0 for partition __consumer_offsets-37 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,627] INFO Completed load of log __consumer_offsets-37 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:22,635] INFO Created log for partition [__consumer_offsets,37] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,676] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2017-10-06 17:26:22,694] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,701] INFO Partition [__consumer_offsets,37] on broker 0: __consumer_offsets-37 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,731] INFO Loading producer state from offset 0 for partition kafkalogger-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,742] INFO Completed load of log kafkalogger-0 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:22,747] INFO Created log for partition [kafkalogger,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,781] INFO Partition [kafkalogger,0] on broker 0: No checkpointed highwatermark is found for partition kafkalogger-0 (kafka.cluster.Partition)
[2017-10-06 17:26:22,799] INFO Replica loaded for partition kafkalogger-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,804] INFO Partition [kafkalogger,0] on broker 0: kafkalogger-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,835] INFO Loading producer state from offset 0 for partition cluster-3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,843] INFO Completed load of log cluster-3-0 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:22,849] INFO Created log for partition [cluster-3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,881] INFO Partition [cluster-3,0] on broker 0: No checkpointed highwatermark is found for partition cluster-3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:22,900] INFO Replica loaded for partition cluster-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:22,906] INFO Partition [cluster-3,0] on broker 0: cluster-3-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:22,941] INFO Loading producer state from offset 0 for partition __consumer_offsets-18 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:22,950] INFO Completed load of log __consumer_offsets-18 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:22,958] INFO Created log for partition [__consumer_offsets,18] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:22,993] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2017-10-06 17:26:23,015] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,022] INFO Partition [__consumer_offsets,18] on broker 0: __consumer_offsets-18 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,053] INFO Loading producer state from offset 0 for partition __consumer_offsets-15 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,061] INFO Completed load of log __consumer_offsets-15 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:26:23,069] INFO Created log for partition [__consumer_offsets,15] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,112] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2017-10-06 17:26:23,123] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,130] INFO Partition [__consumer_offsets,15] on broker 0: __consumer_offsets-15 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,165] INFO Loading producer state from offset 0 for partition test2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,175] INFO Completed load of log test2-0 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:26:23,183] INFO Created log for partition [test2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,246] INFO Partition [test2,0] on broker 0: No checkpointed highwatermark is found for partition test2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:23,264] INFO Replica loaded for partition test2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,273] INFO Partition [test2,0] on broker 0: test2-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,320] INFO Loading producer state from offset 0 for partition __consumer_offsets-34 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,339] INFO Completed load of log __consumer_offsets-34 with 1 log segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2017-10-06 17:26:23,350] INFO Created log for partition [__consumer_offsets,34] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,417] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2017-10-06 17:26:23,426] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,437] INFO Partition [__consumer_offsets,34] on broker 0: __consumer_offsets-34 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,480] INFO Loading producer state from offset 0 for partition test-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,494] INFO Completed load of log test-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2017-10-06 17:26:23,509] INFO Created log for partition [test-topic2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,558] INFO Partition [test-topic2,0] on broker 0: No checkpointed highwatermark is found for partition test-topic2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:23,577] INFO Replica loaded for partition test-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,583] INFO Partition [test-topic2,0] on broker 0: test-topic2-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,623] INFO Loading producer state from offset 0 for partition __consumer_offsets-12 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,632] INFO Completed load of log __consumer_offsets-12 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:23,642] INFO Created log for partition [__consumer_offsets,12] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,685] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2017-10-06 17:26:23,703] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,710] INFO Partition [__consumer_offsets,12] on broker 0: __consumer_offsets-12 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,748] INFO Loading producer state from offset 0 for partition __consumer_offsets-31 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,763] INFO Completed load of log __consumer_offsets-31 with 1 log segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2017-10-06 17:26:23,771] INFO Created log for partition [__consumer_offsets,31] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,810] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2017-10-06 17:26:23,819] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,825] INFO Partition [__consumer_offsets,31] on broker 0: __consumer_offsets-31 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,858] INFO Loading producer state from offset 0 for partition filter-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,865] INFO Completed load of log filter-0 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:23,874] INFO Created log for partition [filter,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:23,913] INFO Partition [filter,0] on broker 0: No checkpointed highwatermark is found for partition filter-0 (kafka.cluster.Partition)
[2017-10-06 17:26:23,935] INFO Replica loaded for partition filter-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:23,942] INFO Partition [filter,0] on broker 0: filter-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:23,977] INFO Loading producer state from offset 0 for partition clusterdb-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:23,986] INFO Completed load of log clusterdb-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:23,992] INFO Created log for partition [clusterdb-topic3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,026] INFO Partition [clusterdb-topic3,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:24,034] INFO Replica loaded for partition clusterdb-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,041] INFO Partition [clusterdb-topic3,0] on broker 0: clusterdb-topic3-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,085] INFO Loading producer state from offset 0 for partition db3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,097] INFO Completed load of log db3-0 with 1 log segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2017-10-06 17:26:24,104] INFO Created log for partition [db3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,140] INFO Partition [db3,0] on broker 0: No checkpointed highwatermark is found for partition db3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:24,161] INFO Replica loaded for partition db3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,166] INFO Partition [db3,0] on broker 0: db3-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,199] INFO Loading producer state from offset 0 for partition __consumer_offsets-9 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,206] INFO Completed load of log __consumer_offsets-9 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:24,215] INFO Created log for partition [__consumer_offsets,9] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,256] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2017-10-06 17:26:24,278] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,288] INFO Partition [__consumer_offsets,9] on broker 0: __consumer_offsets-9 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,322] INFO Loading producer state from offset 0 for partition __consumer_offsets-47 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,331] INFO Completed load of log __consumer_offsets-47 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:24,338] INFO Created log for partition [__consumer_offsets,47] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,374] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2017-10-06 17:26:24,394] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,399] INFO Partition [__consumer_offsets,47] on broker 0: __consumer_offsets-47 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,429] INFO Loading producer state from offset 0 for partition __consumer_offsets-19 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,439] INFO Completed load of log __consumer_offsets-19 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:24,445] INFO Created log for partition [__consumer_offsets,19] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,482] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2017-10-06 17:26:24,499] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,504] INFO Partition [__consumer_offsets,19] on broker 0: __consumer_offsets-19 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,540] INFO Loading producer state from offset 0 for partition __consumer_offsets-28 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,549] INFO Completed load of log __consumer_offsets-28 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:24,557] INFO Created log for partition [__consumer_offsets,28] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,592] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2017-10-06 17:26:24,615] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,621] INFO Partition [__consumer_offsets,28] on broker 0: __consumer_offsets-28 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,652] INFO Loading producer state from offset 0 for partition __consumer_offsets-38 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,662] INFO Completed load of log __consumer_offsets-38 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:24,668] INFO Created log for partition [__consumer_offsets,38] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,704] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2017-10-06 17:26:24,723] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,729] INFO Partition [__consumer_offsets,38] on broker 0: __consumer_offsets-38 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,763] INFO Loading producer state from offset 0 for partition clusterdb2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,772] INFO Completed load of log clusterdb2-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:26:24,779] INFO Created log for partition [clusterdb2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,821] INFO Partition [clusterdb2,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:24,839] INFO Replica loaded for partition clusterdb2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,844] INFO Partition [clusterdb2,0] on broker 0: clusterdb2-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,873] INFO Loading producer state from offset 0 for partition clusterdb-topic6-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,882] INFO Completed load of log clusterdb-topic6-0 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:26:24,888] INFO Created log for partition [clusterdb-topic6,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:24,922] INFO Partition [clusterdb-topic6,0] on broker 0: No checkpointed highwatermark is found for partition clusterdb-topic6-0 (kafka.cluster.Partition)
[2017-10-06 17:26:24,938] INFO Replica loaded for partition clusterdb-topic6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:24,944] INFO Partition [clusterdb-topic6,0] on broker 0: clusterdb-topic6-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:24,975] INFO Loading producer state from offset 0 for partition __consumer_offsets-35 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:24,985] INFO Completed load of log __consumer_offsets-35 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:24,992] INFO Created log for partition [__consumer_offsets,35] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,027] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2017-10-06 17:26:25,034] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,041] INFO Partition [__consumer_offsets,35] on broker 0: __consumer_offsets-35 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,083] INFO Loading producer state from offset 0 for partition cluster3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,091] INFO Completed load of log cluster3-0 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:25,099] INFO Created log for partition [cluster3,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,132] INFO Partition [cluster3,0] on broker 0: No checkpointed highwatermark is found for partition cluster3-0 (kafka.cluster.Partition)
[2017-10-06 17:26:25,154] INFO Replica loaded for partition cluster3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,160] INFO Partition [cluster3,0] on broker 0: cluster3-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,189] INFO Loading producer state from offset 0 for partition __consumer_offsets-44 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,199] INFO Completed load of log __consumer_offsets-44 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:25,206] INFO Created log for partition [__consumer_offsets,44] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,243] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2017-10-06 17:26:25,262] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,267] INFO Partition [__consumer_offsets,44] on broker 0: __consumer_offsets-44 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,300] INFO Loading producer state from offset 0 for partition __consumer_offsets-6 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,308] INFO Completed load of log __consumer_offsets-6 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:25,315] INFO Created log for partition [__consumer_offsets,6] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,348] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2017-10-06 17:26:25,356] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,363] INFO Partition [__consumer_offsets,6] on broker 0: __consumer_offsets-6 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,402] INFO Loading producer state from offset 0 for partition __consumer_offsets-25 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,414] INFO Completed load of log __consumer_offsets-25 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:25,423] INFO Created log for partition [__consumer_offsets,25] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,457] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2017-10-06 17:26:25,480] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,484] INFO Partition [__consumer_offsets,25] on broker 0: __consumer_offsets-25 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,519] INFO Loading producer state from offset 0 for partition __consumer_offsets-16 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,527] INFO Completed load of log __consumer_offsets-16 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:25,534] INFO Created log for partition [__consumer_offsets,16] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,568] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2017-10-06 17:26:25,577] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,584] INFO Partition [__consumer_offsets,16] on broker 0: __consumer_offsets-16 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,619] INFO Loading producer state from offset 0 for partition __consumer_offsets-22 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,627] INFO Completed load of log __consumer_offsets-22 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:25,635] INFO Created log for partition [__consumer_offsets,22] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,678] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2017-10-06 17:26:25,699] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,703] INFO Partition [__consumer_offsets,22] on broker 0: __consumer_offsets-22 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,739] INFO Loading producer state from offset 0 for partition __consumer_offsets-41 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,748] INFO Completed load of log __consumer_offsets-41 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:25,758] INFO Created log for partition [__consumer_offsets,41] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,795] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2017-10-06 17:26:25,816] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,822] INFO Partition [__consumer_offsets,41] on broker 0: __consumer_offsets-41 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,851] INFO Loading producer state from offset 0 for partition db2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,862] INFO Completed load of log db2-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:26:25,868] INFO Created log for partition [db2,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:25,920] INFO Partition [db2,0] on broker 0: No checkpointed highwatermark is found for partition db2-0 (kafka.cluster.Partition)
[2017-10-06 17:26:25,926] INFO Replica loaded for partition db2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:25,931] INFO Partition [db2,0] on broker 0: db2-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:25,966] INFO Loading producer state from offset 0 for partition __consumer_offsets-32 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:25,977] INFO Completed load of log __consumer_offsets-32 with 1 log segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2017-10-06 17:26:25,983] INFO Created log for partition [__consumer_offsets,32] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:26,029] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2017-10-06 17:26:26,038] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:26,045] INFO Partition [__consumer_offsets,32] on broker 0: __consumer_offsets-32 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:26,080] INFO Loading producer state from offset 0 for partition test-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:26,091] INFO Completed load of log test-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:26:26,098] INFO Created log for partition [test-topic4,0] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:26,132] INFO Partition [test-topic4,0] on broker 0: No checkpointed highwatermark is found for partition test-topic4-0 (kafka.cluster.Partition)
[2017-10-06 17:26:26,154] INFO Replica loaded for partition test-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:26,160] INFO Partition [test-topic4,0] on broker 0: test-topic4-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:26,187] INFO Loading producer state from offset 0 for partition __consumer_offsets-3 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:26,199] INFO Completed load of log __consumer_offsets-3 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:26:26,206] INFO Created log for partition [__consumer_offsets,3] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:26,247] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2017-10-06 17:26:26,266] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:26,271] INFO Partition [__consumer_offsets,3] on broker 0: __consumer_offsets-3 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:26,311] INFO Loading producer state from offset 0 for partition __consumer_offsets-13 with message format version 2 (kafka.log.Log)
[2017-10-06 17:26:26,320] INFO Completed load of log __consumer_offsets-13 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:26:26,327] INFO Created log for partition [__consumer_offsets,13] in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 0.11.0-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2017-10-06 17:26:26,361] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2017-10-06 17:26:26,381] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:26:26,385] INFO Partition [__consumer_offsets,13] on broker 0: __consumer_offsets-13 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:26:26,429] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,444] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,465] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,484] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,481] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-25 in 33 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,499] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,517] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,525] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,534] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,567] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,556] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,580] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,589] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,601] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,610] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,622] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,630] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,642] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,650] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,662] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,670] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,683] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,689] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,701] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,709] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,723] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,732] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,743] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,751] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,764] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,772] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,782] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,790] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,802] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,810] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,822] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,829] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,841] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,849] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,859] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,869] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,881] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-15 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,889] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,900] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,906] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,916] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,924] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,937] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,943] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,954] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,964] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,974] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-45 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,980] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,989] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-22 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:26,996] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,015] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,022] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,031] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,039] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,050] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,058] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,075] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,084] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,095] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,102] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,113] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,120] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,128] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,136] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,156] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,164] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,173] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,182] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,192] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,200] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,209] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,217] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,232] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,240] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,251] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,260] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,270] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,278] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,295] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,302] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,311] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,320] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,328] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,337] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,352] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,360] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,370] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,379] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,390] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,398] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,413] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,421] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,430] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,451] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:26:27,465] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:27:31,720] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:27:31,728] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:27:31,861] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 17:27:31,891] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:27:31,923] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:27:31,943] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:27:31,959] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:27:31,977] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:32,011] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:32,011] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:32,019] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:33,008] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:33,008] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:33,027] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:34,009] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:34,009] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:27:34,024] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:27:34,035] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,042] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,042] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,062] INFO [Transaction Coordinator 0]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:27:34,072] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 23000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:27:34,080] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:27:34,088] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:27:34,096] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:27:34,096] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:27:34,114] INFO [Transaction Coordinator 0]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:27:34,125] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:27:34,131] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,155] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,155] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,173] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,355] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,355] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,368] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:27:34,376] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:27:34,381] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:27:34,392] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:27:34,399] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,555] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,555] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,568] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,756] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,756] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,767] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,956] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,956] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:27:34,978] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:27:34,984] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:27:35,889] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:27:35,895] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:27:35,898] INFO Processed session termination for sessionid: 0x15ef394c58e0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:27:35,909] INFO Session: 0x15ef394c58e0001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:27:35,911] INFO EventThread shut down for session: 0x15ef394c58e0001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:35,918] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:27:35,910] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef394c58e0001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:27:35,934] INFO Closed socket connection for client /127.0.0.1:63309 which had sessionid 0x15ef394c58e0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:27:42,670] WARN Session 0x15ef394c58e0000 for server 127.0.0.1/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:42,836] INFO zookeeper state changed (Disconnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:27:43,824] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:44,843] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:46,429] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:47,434] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:47,822] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:48,833] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:50,451] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:50,646] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:27:50,659] INFO [Kafka Server 2], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:27:51,460] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:51,581] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:27:51,824] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:52,835] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:54,093] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:55,105] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:55,327] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:56,336] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:57,779] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:27:58,801] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:27:59,767] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:28:00,786] WARN Session 0x15ef394c58e0000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2017-10-06 17:28:02,736] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:13,328] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:32:13,335] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:32:13,338] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:32:13,341] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:32:13,344] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:32:13,367] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:32:13,372] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:32:13,387] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,391] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,395] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,399] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,403] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,407] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,548] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,561] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,571] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,575] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,581] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,584] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,589] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,593] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,597] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,611] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,614] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,617] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:13,643] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:32:13,804] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:32:13,808] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:32:13,814] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:32:13,818] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:32:21,003] INFO Expiring session 0x15ef394c58e0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:21,035] INFO Processed session termination for sessionid: 0x15ef394c58e0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:21,053] INFO Creating new log file: log.c30 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 17:32:25,073] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:32:25,092] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:32:25,763] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:32:25,814] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:32:25,883] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:32:25,905] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:32:25,922] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:32:25,929] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,945] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,957] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,970] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,982] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,712] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:32:26,000] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:32:26,046] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,074] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,088] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,103] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,112] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,281] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:32:26,305] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:32:26,354] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:32:26,378] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,398] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,421] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,440] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,458] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:25,998] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,490] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,548] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,583] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,599] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,616] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,636] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,654] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,671] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,131] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,692] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,712] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,693] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,748] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,763] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,780] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,793] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,792] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:26,806] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,815] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,814] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:26,831] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,847] INFO Accepted socket connection from /127.0.0.1:63392 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:32:26,848] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:26,849] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,892] INFO Client attempting to establish new session at /127.0.0.1:63392 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:26,887] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,925] INFO Established session 0x15ef39a5e990000 with negotiated timeout 6000 for client /127.0.0.1:63392 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:26,929] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef39a5e990000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:26,957] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:26,482] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:26,982] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,016] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,009] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:27,040] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,052] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,060] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,056] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,072] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,082] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,080] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63395 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:32:27,082] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,093] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,107] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,110] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63395 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:27,117] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:27,135] INFO Established session 0x15ef39a5e990001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63395 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:27,138] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef39a5e990001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,172] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:27,211] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:27,226] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,241] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,239] INFO Accepted socket connection from /127.0.0.1:63398 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:32:27,268] INFO Client attempting to establish new session at /127.0.0.1:63398 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:27,283] INFO Established session 0x15ef39a5e990002 with negotiated timeout 6000 for client /127.0.0.1:63398 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:32:27,288] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef39a5e990002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:27,305] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:32:27,499] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:32:27,734] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:27,734] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:27,722] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:32:27,734] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:27,968] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:32:28,035] WARN No meta.properties file under dir C:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:32:28,233] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,234] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,234] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,315] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:32:28,449] INFO Logs loading complete in 76 ms. (kafka.log.LogManager)
[2017-10-06 17:32:28,632] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,632] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,632] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:28,715] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:32:28,927] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:32:29,037] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:32:29,114] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:32:29,167] INFO Logs loading complete in 37 ms. (kafka.log.LogManager)
[2017-10-06 17:32:29,180] INFO Loading producer state from offset 0 for partition cluster-1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,243] INFO Completed load of log cluster-1-0 with 1 log segments, log start offset 0 and log end offset 0 in 254 ms (kafka.log.Log)
[2017-10-06 17:32:29,261] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2017-10-06 17:32:29,282] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:32:29,302] INFO Loading producer state from offset 0 for partition cluster-2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,317] INFO Completed load of log cluster-2-0 with 1 log segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2017-10-06 17:32:29,348] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:32:29,356] INFO Loading producer state from offset 0 for partition cluster-3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,363] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:32:29,365] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,365] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,376] INFO Completed load of log cluster-3-0 with 1 log segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2017-10-06 17:32:29,365] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,521] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 17:32:29,491] INFO Loading producer state from offset 0 for partition cluster1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,530] INFO Completed load of log cluster1-0 with 1 log segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2017-10-06 17:32:29,542] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:32:29,590] INFO Loading producer state from offset 0 for partition cluster2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,600] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,700] INFO Completed load of log cluster2-0 with 1 log segments, log start offset 0 and log end offset 0 in 134 ms (kafka.log.Log)
[2017-10-06 17:32:29,693] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:29,603] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,785] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,601] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,811] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:29,746] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:29,781] INFO Loading producer state from offset 0 for partition cluster3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,849] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:29,785] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,889] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:25000,blockEndProducerId:25999) by writing to Zk with path version 26 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:32:29,853] INFO Completed load of log cluster3-0 with 1 log segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2017-10-06 17:32:29,924] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 41 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:29,785] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:29,959] INFO Loading producer state from offset 0 for partition clusterdb-topic1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:29,967] INFO [Transaction Coordinator 2]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:30,033] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:30,034] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:30,157] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:30,024] INFO Completed load of log clusterdb-topic1-0 with 1 log segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2017-10-06 17:32:30,030] INFO [Transaction Coordinator 2]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:30,033] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:30,213] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:30,254] INFO Loading producer state from offset 0 for partition clusterdb-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:30,271] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:30,286] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:30,287] INFO Completed load of log clusterdb-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2017-10-06 17:32:30,345] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:26000,blockEndProducerId:26999) by writing to Zk with path version 27 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:32:30,339] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:32:30,384] INFO Loading producer state from offset 0 for partition clusterdb-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:30,507] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:30,452] INFO Completed load of log clusterdb-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2017-10-06 17:32:30,534] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:30,575] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:30,571] INFO Loading producer state from offset 0 for partition clusterdb-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:30,672] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:32:30,655] INFO Completed load of log clusterdb-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 107 ms (kafka.log.Log)
[2017-10-06 17:32:30,734] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:30,819] INFO Loading producer state from offset 0 for partition clusterdb-topic5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:30,853] INFO Completed load of log clusterdb-topic5-0 with 1 log segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2017-10-06 17:32:30,845] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990000 type:create cxid:0xdb zxid:0xc38 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:30,866] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990000 type:create cxid:0xdc zxid:0xc39 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:30,890] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:30,964] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:32:30,949] INFO Loading producer state from offset 0 for partition clusterdb-topic6-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,042] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:31,054] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:31,069] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2017-10-06 17:32:31,044] INFO Completed load of log clusterdb-topic6-0 with 1 log segments, log start offset 0 and log end offset 0 in 163 ms (kafka.log.Log)
[2017-10-06 17:32:31,102] INFO Loading producer state from offset 0 for partition clusterdb-topic7-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,153] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:31,127] INFO Completed load of log clusterdb-topic7-0 with 1 log segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2017-10-06 17:32:31,165] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990002 type:create cxid:0x62 zxid:0xc3b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:31,194] INFO Loading producer state from offset 0 for partition clusterdb1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,216] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990002 type:create cxid:0x63 zxid:0xc3c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:31,226] INFO Completed load of log clusterdb1-0 with 1 log segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2017-10-06 17:32:31,247] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:31,270] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:32:31,279] WARN No meta.properties file under dir C:\tmp\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2017-10-06 17:32:31,316] INFO Loading producer state from offset 0 for partition clusterdb2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,348] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:31,332] INFO Completed load of log clusterdb2-0 with 1 log segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2017-10-06 17:32:31,367] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:31,415] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 17:32:31,414] INFO Loading producer state from offset 0 for partition clusterdb3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,425] INFO Completed load of log clusterdb3-0 with 1 log segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2017-10-06 17:32:31,453] INFO Loading producer state from offset 0 for partition db-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,463] INFO Completed load of log db-0 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:32:31,509] INFO Loading producer state from offset 0 for partition db1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,542] INFO Completed load of log db1-0 with 1 log segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2017-10-06 17:32:31,587] INFO Loading producer state from offset 0 for partition db2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,630] INFO Completed load of log db2-0 with 1 log segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2017-10-06 17:32:31,763] INFO Loading producer state from offset 0 for partition db3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,789] INFO Completed load of log db3-0 with 1 log segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2017-10-06 17:32:31,832] INFO Loading producer state from offset 0 for partition demo-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,844] INFO Completed load of log demo-0 with 1 log segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2017-10-06 17:32:31,869] INFO Loading producer state from offset 0 for partition demo2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,884] INFO Completed load of log demo2-0 with 1 log segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2017-10-06 17:32:31,942] INFO Loading producer state from offset 0 for partition demo3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:31,950] INFO Completed load of log demo3-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:32:32,035] INFO Loading producer state from offset 0 for partition demo5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,049] INFO Completed load of log demo5-0 with 1 log segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2017-10-06 17:32:32,091] INFO Loading producer state from offset 0 for partition filter-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,102] INFO Completed load of log filter-0 with 1 log segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2017-10-06 17:32:32,139] INFO Loading producer state from offset 0 for partition kafkalogger-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,149] INFO Completed load of log kafkalogger-0 with 1 log segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2017-10-06 17:32:32,147] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990000 type:delete cxid:0x1c0 zxid:0xc3e txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:32,191] INFO Loading producer state from offset 0 for partition kafkalogger2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,201] INFO Completed load of log kafkalogger2-0 with 1 log segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2017-10-06 17:32:32,248] INFO Loading producer state from offset 0 for partition test-topic-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,286] INFO Completed load of log test-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2017-10-06 17:32:32,392] INFO Loading producer state from offset 0 for partition test-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,452] INFO Completed load of log test-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2017-10-06 17:32:32,708] INFO Loading producer state from offset 0 for partition test-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,765] INFO Completed load of log test-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2017-10-06 17:32:32,877] INFO Loading producer state from offset 0 for partition test-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:32,924] INFO Completed load of log test-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2017-10-06 17:32:33,016] INFO Loading producer state from offset 0 for partition test1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,081] INFO Completed load of log test1-0 with 1 log segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2017-10-06 17:32:33,111] INFO Loading producer state from offset 0 for partition test2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,147] INFO Completed load of log test2-0 with 1 log segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2017-10-06 17:32:33,195] INFO Loading producer state from offset 0 for partition test3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,202] INFO Completed load of log test3-0 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:32:33,240] INFO Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,248] INFO Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:32:33,270] INFO Loading producer state from offset 0 for partition __consumer_offsets-1 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,276] INFO Completed load of log __consumer_offsets-1 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:33,299] INFO Loading producer state from offset 0 for partition __consumer_offsets-10 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,305] INFO Completed load of log __consumer_offsets-10 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:33,327] INFO Loading producer state from offset 0 for partition __consumer_offsets-11 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,332] INFO Completed load of log __consumer_offsets-11 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:33,355] INFO Loading producer state from offset 0 for partition __consumer_offsets-12 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,361] INFO Completed load of log __consumer_offsets-12 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:33,384] INFO Loading producer state from offset 0 for partition __consumer_offsets-13 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,390] INFO Completed load of log __consumer_offsets-13 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:33,416] INFO Loading producer state from offset 0 for partition __consumer_offsets-14 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,426] INFO Completed load of log __consumer_offsets-14 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:32:33,449] INFO Loading producer state from offset 0 for partition __consumer_offsets-15 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,455] INFO Completed load of log __consumer_offsets-15 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:33,483] INFO Loading producer state from offset 0 for partition __consumer_offsets-16 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,489] INFO Completed load of log __consumer_offsets-16 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,514] INFO Loading producer state from offset 0 for partition __consumer_offsets-17 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,522] INFO Completed load of log __consumer_offsets-17 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,549] INFO Loading producer state from offset 0 for partition __consumer_offsets-18 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,561] INFO Completed load of log __consumer_offsets-18 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:32:33,589] INFO Loading producer state from offset 0 for partition __consumer_offsets-19 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,600] INFO Completed load of log __consumer_offsets-19 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:32:33,626] INFO Loading producer state from offset 0 for partition __consumer_offsets-2 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,635] INFO Completed load of log __consumer_offsets-2 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:32:33,668] INFO Loading producer state from offset 0 for partition __consumer_offsets-20 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,678] INFO Completed load of log __consumer_offsets-20 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:32:33,712] INFO Loading producer state from offset 0 for partition __consumer_offsets-21 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,719] INFO Completed load of log __consumer_offsets-21 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,746] INFO Loading producer state from offset 0 for partition __consumer_offsets-22 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,753] INFO Completed load of log __consumer_offsets-22 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:32:33,783] INFO Loading producer state from offset 0 for partition __consumer_offsets-23 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,789] INFO Completed load of log __consumer_offsets-23 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:32:33,815] INFO Loading producer state from offset 0 for partition __consumer_offsets-24 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,822] INFO Completed load of log __consumer_offsets-24 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,849] INFO Loading producer state from offset 0 for partition __consumer_offsets-25 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,855] INFO Completed load of log __consumer_offsets-25 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:33,880] INFO Loading producer state from offset 0 for partition __consumer_offsets-26 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,886] INFO Completed load of log __consumer_offsets-26 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:33,910] INFO Loading producer state from offset 0 for partition __consumer_offsets-27 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,917] INFO Completed load of log __consumer_offsets-27 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,943] INFO Loading producer state from offset 0 for partition __consumer_offsets-28 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,949] INFO Completed load of log __consumer_offsets-28 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:32:33,969] INFO Loading producer state from offset 0 for partition __consumer_offsets-29 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:33,975] INFO Completed load of log __consumer_offsets-29 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:33,999] INFO Loading producer state from offset 0 for partition __consumer_offsets-3 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,004] INFO Completed load of log __consumer_offsets-3 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:34,027] INFO Loading producer state from offset 0 for partition __consumer_offsets-30 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,033] INFO Completed load of log __consumer_offsets-30 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:34,055] INFO Loading producer state from offset 0 for partition __consumer_offsets-31 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,061] INFO Completed load of log __consumer_offsets-31 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:34,083] INFO Loading producer state from offset 0 for partition __consumer_offsets-32 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,088] INFO Completed load of log __consumer_offsets-32 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:34,111] INFO Loading producer state from offset 0 for partition __consumer_offsets-33 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,117] INFO Completed load of log __consumer_offsets-33 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,137] INFO Loading producer state from offset 0 for partition __consumer_offsets-34 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,143] INFO Completed load of log __consumer_offsets-34 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:34,167] INFO Loading producer state from offset 0 for partition __consumer_offsets-35 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,172] INFO Completed load of log __consumer_offsets-35 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:34,199] INFO Loading producer state from offset 0 for partition __consumer_offsets-36 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,205] INFO Completed load of log __consumer_offsets-36 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:34,226] INFO Loading producer state from offset 0 for partition __consumer_offsets-37 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,231] INFO Completed load of log __consumer_offsets-37 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:32:34,251] INFO Loading producer state from offset 0 for partition __consumer_offsets-38 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,258] INFO Completed load of log __consumer_offsets-38 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,279] INFO Loading producer state from offset 0 for partition __consumer_offsets-39 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,285] INFO Completed load of log __consumer_offsets-39 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,305] INFO Loading producer state from offset 0 for partition __consumer_offsets-4 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,311] INFO Completed load of log __consumer_offsets-4 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:34,331] INFO Loading producer state from offset 0 for partition __consumer_offsets-40 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,337] INFO Completed load of log __consumer_offsets-40 with 1 log segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2017-10-06 17:32:34,356] INFO Loading producer state from offset 0 for partition __consumer_offsets-41 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,363] INFO Completed load of log __consumer_offsets-41 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:34,382] INFO Loading producer state from offset 0 for partition __consumer_offsets-42 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,387] INFO Completed load of log __consumer_offsets-42 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:34,405] INFO Loading producer state from offset 0 for partition __consumer_offsets-43 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,410] INFO Completed load of log __consumer_offsets-43 with 1 log segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2017-10-06 17:32:34,426] INFO Loading producer state from offset 0 for partition __consumer_offsets-44 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,430] INFO Completed load of log __consumer_offsets-44 with 1 log segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2017-10-06 17:32:34,447] INFO Loading producer state from offset 0 for partition __consumer_offsets-45 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,451] INFO Completed load of log __consumer_offsets-45 with 1 log segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2017-10-06 17:32:34,469] INFO Loading producer state from offset 0 for partition __consumer_offsets-46 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,474] INFO Completed load of log __consumer_offsets-46 with 1 log segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2017-10-06 17:32:34,490] INFO Loading producer state from offset 0 for partition __consumer_offsets-47 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,495] INFO Completed load of log __consumer_offsets-47 with 1 log segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2017-10-06 17:32:34,515] INFO Loading producer state from offset 0 for partition __consumer_offsets-48 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,521] INFO Completed load of log __consumer_offsets-48 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,542] INFO Loading producer state from offset 0 for partition __consumer_offsets-49 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,548] INFO Completed load of log __consumer_offsets-49 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,574] INFO Loading producer state from offset 0 for partition __consumer_offsets-5 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,580] INFO Completed load of log __consumer_offsets-5 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:34,603] INFO Loading producer state from offset 0 for partition __consumer_offsets-6 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,608] INFO Completed load of log __consumer_offsets-6 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:32:34,632] INFO Loading producer state from offset 0 for partition __consumer_offsets-7 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,637] INFO Completed load of log __consumer_offsets-7 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:32:34,656] INFO Loading producer state from offset 0 for partition __consumer_offsets-8 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,662] INFO Completed load of log __consumer_offsets-8 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:32:34,683] INFO Loading producer state from offset 0 for partition __consumer_offsets-9 with message format version 2 (kafka.log.Log)
[2017-10-06 17:32:34,687] INFO Completed load of log __consumer_offsets-9 with 1 log segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2017-10-06 17:32:34,696] INFO Logs loading complete in 5967 ms. (kafka.log.LogManager)
[2017-10-06 17:32:34,776] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:32:34,781] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:32:34,855] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2017-10-06 17:32:34,861] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:32:34,889] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:34,894] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:34,895] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:34,971] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:34,971] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:34,971] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:35,067] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:35,084] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:35,105] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:35,132] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:27000,blockEndProducerId:27999) by writing to Zk with path version 28 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:32:35,223] INFO [Transaction Coordinator 0]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:35,232] INFO [Transaction Coordinator 0]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:35,232] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:35,308] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:32:35,614] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:35,628] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990001 type:create cxid:0x62 zxid:0xc40 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:35,642] INFO Got user-level KeeperException when processing sessionid:0x15ef39a5e990001 type:create cxid:0x63 zxid:0xc41 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:35,674] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:32:35,688] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:32:35,715] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:35,777] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:32:35,813] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2017-10-06 17:32:37,271] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,314] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,340] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,364] INFO Replica loaded for partition cluster-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,377] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,399] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,414] INFO Replica loaded for partition cluster2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,439] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,460] INFO Replica loaded for partition demo3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,483] INFO Replica loaded for partition test1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,518] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,655] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,682] INFO Replica loaded for partition db-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,705] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,720] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,735] INFO Replica loaded for partition clusterdb-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,774] INFO Replica loaded for partition clusterdb1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,794] INFO Replica loaded for partition kafkalogger2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,803] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,815] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,829] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,842] INFO Replica loaded for partition clusterdb-topic5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,862] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,871] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,884] INFO Replica loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,898] INFO Replica loaded for partition demo2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,909] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,920] INFO Replica loaded for partition test-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,928] INFO Replica loaded for partition demo5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,940] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,948] INFO Replica loaded for partition db1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,961] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,972] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,988] INFO Replica loaded for partition cluster-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:37,998] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,012] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,022] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,037] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,047] INFO Replica loaded for partition clusterdb-topic7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,060] INFO Replica loaded for partition cluster1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,069] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,081] INFO Replica loaded for partition clusterdb3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,091] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,104] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,113] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,123] INFO Replica loaded for partition clusterdb-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,131] INFO Replica loaded for partition clusterdb-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,144] INFO Replica loaded for partition demo-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,156] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,166] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,175] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,189] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,198] INFO Replica loaded for partition kafkalogger-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,208] INFO Replica loaded for partition cluster-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,222] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,233] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,244] INFO Replica loaded for partition test2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,259] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,268] INFO Replica loaded for partition test-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,279] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,290] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,302] INFO Replica loaded for partition filter-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,311] INFO Replica loaded for partition clusterdb-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,327] INFO Replica loaded for partition db3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,337] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,348] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,368] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,385] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,402] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,414] INFO Replica loaded for partition clusterdb2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,423] INFO Replica loaded for partition clusterdb-topic6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,438] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,447] INFO Replica loaded for partition cluster3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,460] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,471] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,482] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,491] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,502] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,520] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,558] INFO Replica loaded for partition db2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,572] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,592] INFO Replica loaded for partition test-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,610] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,628] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:32:38,640] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:38,658] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:38,764] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,db1-0,__consumer_offsets-30,clusterdb-topic2-0,cluster-3-0,__consumer_offsets-8,__consumer_offsets-21,clusterdb-topic1-0,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,cluster1-0,cluster-2-0,filter-0,clusterdb2-0,__consumer_offsets-25,__consumer_offsets-35,test3-0,demo2-0,__consumer_offsets-41,__consumer_offsets-33,clusterdb-topic5-0,__consumer_offsets-23,__consumer_offsets-49,test-topic3-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,demo5-0,__consumer_offsets-31,clusterdb-topic6-0,__consumer_offsets-36,__consumer_offsets-42,cluster-1-0,__consumer_offsets-3,__consumer_offsets-18,clusterdb1-0,test1-0,cluster3-0,__consumer_offsets-37,demo-0,clusterdb-topic7-0,__consumer_offsets-15,__consumer_offsets-24,db2-0,db-0,clusterdb-topic4-0,demo3-0,test-topic2-0,__consumer_offsets-38,clusterdb3-0,__consumer_offsets-17,__consumer_offsets-48,kafkalogger-0,__consumer_offsets-19,__consumer_offsets-11,cluster2-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,db3-0,test-topic-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,clusterdb-topic3-0,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,test-topic4-0,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,test2-0,__consumer_offsets-32,kafkalogger2-0,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:38,871] INFO Partition [__consumer_offsets,0] on broker 0: __consumer_offsets-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,894] INFO Partition [__consumer_offsets,29] on broker 0: __consumer_offsets-29 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,905] INFO Partition [__consumer_offsets,48] on broker 0: __consumer_offsets-48 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,916] INFO Partition [cluster-2,0] on broker 0: cluster-2-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,927] INFO Partition [__consumer_offsets,10] on broker 0: __consumer_offsets-10 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,940] INFO Partition [__consumer_offsets,45] on broker 0: __consumer_offsets-45 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,947] INFO Partition [cluster2,0] on broker 0: cluster2-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,958] INFO Partition [__consumer_offsets,26] on broker 0: __consumer_offsets-26 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,968] INFO Partition [demo3,0] on broker 0: demo3-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,975] INFO Partition [test1,0] on broker 0: test1-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,985] INFO Partition [__consumer_offsets,7] on broker 0: __consumer_offsets-7 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:38,994] INFO Partition [__consumer_offsets,42] on broker 0: __consumer_offsets-42 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,008] INFO Partition [db,0] on broker 0: db-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,019] INFO Partition [__consumer_offsets,4] on broker 0: __consumer_offsets-4 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,027] INFO Partition [__consumer_offsets,23] on broker 0: __consumer_offsets-23 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,041] INFO Partition [clusterdb-topic2,0] on broker 0: clusterdb-topic2-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,048] INFO Partition [clusterdb1,0] on broker 0: clusterdb1-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,061] INFO Partition [kafkalogger2,0] on broker 0: kafkalogger2-0 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,068] INFO Partition [__consumer_offsets,1] on broker 0: __consumer_offsets-1 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,080] INFO Partition [__consumer_offsets,20] on broker 0: __consumer_offsets-20 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,087] INFO Partition [__consumer_offsets,39] on broker 0: __consumer_offsets-39 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,101] INFO Partition [clusterdb-topic5,0] on broker 0: clusterdb-topic5-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,109] INFO Partition [__consumer_offsets,17] on broker 0: __consumer_offsets-17 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,121] INFO Partition [__consumer_offsets,36] on broker 0: __consumer_offsets-36 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,130] INFO Partition [test-topic,0] on broker 0: test-topic-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,143] INFO Partition [demo2,0] on broker 0: demo2-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,149] INFO Partition [__consumer_offsets,14] on broker 0: __consumer_offsets-14 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,162] INFO Partition [test-topic3,0] on broker 0: test-topic3-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,170] INFO Partition [demo5,0] on broker 0: demo5-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,179] INFO Partition [test3,0] on broker 0: test3-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,184] INFO Partition [db1,0] on broker 0: db1-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,194] INFO Partition [__consumer_offsets,33] on broker 0: __consumer_offsets-33 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,204] INFO Partition [__consumer_offsets,49] on broker 0: __consumer_offsets-49 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,212] INFO Partition [cluster-1,0] on broker 0: cluster-1-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,221] INFO Partition [__consumer_offsets,11] on broker 0: __consumer_offsets-11 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,230] INFO Partition [__consumer_offsets,30] on broker 0: __consumer_offsets-30 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,238] INFO Partition [__consumer_offsets,46] on broker 0: __consumer_offsets-46 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,250] INFO Partition [__consumer_offsets,27] on broker 0: __consumer_offsets-27 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,261] INFO Partition [clusterdb-topic7,0] on broker 0: clusterdb-topic7-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,270] INFO Partition [cluster1,0] on broker 0: cluster1-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,279] INFO Partition [__consumer_offsets,8] on broker 0: __consumer_offsets-8 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,293] INFO Partition [clusterdb3,0] on broker 0: clusterdb3-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,302] INFO Partition [__consumer_offsets,24] on broker 0: __consumer_offsets-24 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,314] INFO Partition [__consumer_offsets,43] on broker 0: __consumer_offsets-43 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,323] INFO Partition [__consumer_offsets,5] on broker 0: __consumer_offsets-5 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,330] INFO Partition [clusterdb-topic1,0] on broker 0: clusterdb-topic1-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,340] INFO Partition [clusterdb-topic4,0] on broker 0: clusterdb-topic4-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,353] INFO Partition [demo,0] on broker 0: demo-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,361] INFO Partition [__consumer_offsets,21] on broker 0: __consumer_offsets-21 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,369] INFO Partition [__consumer_offsets,40] on broker 0: __consumer_offsets-40 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,375] INFO Partition [__consumer_offsets,2] on broker 0: __consumer_offsets-2 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,390] INFO Partition [__consumer_offsets,37] on broker 0: __consumer_offsets-37 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,400] INFO Partition [kafkalogger,0] on broker 0: kafkalogger-0 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,410] INFO Partition [cluster-3,0] on broker 0: cluster-3-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,420] INFO Partition [__consumer_offsets,18] on broker 0: __consumer_offsets-18 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,430] INFO Partition [__consumer_offsets,15] on broker 0: __consumer_offsets-15 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,439] INFO Partition [test2,0] on broker 0: test2-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,451] INFO Partition [__consumer_offsets,34] on broker 0: __consumer_offsets-34 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,461] INFO Partition [test-topic2,0] on broker 0: test-topic2-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,467] INFO Partition [__consumer_offsets,12] on broker 0: __consumer_offsets-12 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,474] INFO Partition [__consumer_offsets,31] on broker 0: __consumer_offsets-31 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,483] INFO Partition [filter,0] on broker 0: filter-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,489] INFO Partition [clusterdb-topic3,0] on broker 0: clusterdb-topic3-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,498] INFO Partition [db3,0] on broker 0: db3-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,509] INFO Partition [__consumer_offsets,9] on broker 0: __consumer_offsets-9 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,520] INFO Partition [__consumer_offsets,47] on broker 0: __consumer_offsets-47 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,528] INFO Partition [__consumer_offsets,19] on broker 0: __consumer_offsets-19 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,539] INFO Partition [__consumer_offsets,28] on broker 0: __consumer_offsets-28 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,546] INFO Partition [__consumer_offsets,38] on broker 0: __consumer_offsets-38 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,558] INFO Partition [clusterdb2,0] on broker 0: clusterdb2-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,567] INFO Partition [clusterdb-topic6,0] on broker 0: clusterdb-topic6-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,580] INFO Partition [__consumer_offsets,35] on broker 0: __consumer_offsets-35 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,588] INFO Partition [cluster3,0] on broker 0: cluster3-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,599] INFO Partition [__consumer_offsets,44] on broker 0: __consumer_offsets-44 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,607] INFO Partition [__consumer_offsets,6] on broker 0: __consumer_offsets-6 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,619] INFO Partition [__consumer_offsets,25] on broker 0: __consumer_offsets-25 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,628] INFO Partition [__consumer_offsets,16] on broker 0: __consumer_offsets-16 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,639] INFO Partition [__consumer_offsets,22] on broker 0: __consumer_offsets-22 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,646] INFO Partition [__consumer_offsets,41] on broker 0: __consumer_offsets-41 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,660] INFO Partition [db2,0] on broker 0: db2-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,668] INFO Partition [__consumer_offsets,32] on broker 0: __consumer_offsets-32 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,680] INFO Partition [test-topic4,0] on broker 0: test-topic4-0 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,687] INFO Partition [__consumer_offsets,3] on broker 0: __consumer_offsets-3 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,702] INFO Partition [__consumer_offsets,13] on broker 0: __consumer_offsets-13 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:32:39,727] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,742] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,751] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,763] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,772] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,776] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-25 in 32 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,782] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,792] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,800] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,810] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,819] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,833] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,842] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,851] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,858] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,873] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,880] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,891] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,900] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,909] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,916] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,934] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,942] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,952] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,960] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,971] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,980] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,989] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:39,995] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,011] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,020] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,030] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,037] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,053] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,060] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,068] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,074] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,083] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,091] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,102] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,109] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,121] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,127] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,136] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,145] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,153] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,161] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,171] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,181] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,191] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,198] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,211] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,218] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,231] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,240] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,252] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-22 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,260] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,268] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,274] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,285] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,291] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,302] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,310] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,321] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,328] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,339] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,344] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,355] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-47 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,362] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,373] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,381] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,389] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,395] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,406] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,414] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,424] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,430] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,440] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,447] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,455] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,463] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,472] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,480] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,496] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,488] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,512] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,534] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,522] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,545] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,554] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,563] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,574] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,584] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,593] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,644] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,651] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,664] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,677] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,690] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:40,703] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:32:45,231] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:32:45,243] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:32:45,376] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 17:32:45,391] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:32:45,447] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:32:45,459] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:45,475] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:45,493] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:45,979] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:45,979] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:45,984] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:46,978] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:46,978] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:47,002] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:47,979] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:47,979] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:47,995] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:32:48,008] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,090] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,090] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,104] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:48,118] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 26000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:32:48,126] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:32:48,133] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:48,144] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:48,144] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:48,165] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:48,177] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:48,184] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,278] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,278] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,298] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,480] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,480] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,498] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:48,507] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:32:48,518] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:48,531] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:48,541] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,678] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,678] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,688] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,882] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,882] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,889] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,889] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,907] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:48,940] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:32:48,948] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:32:48,992] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:32:49,014] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:32:49,022] INFO Processed session termination for sessionid: 0x15ef39a5e990002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:49,038] INFO Session: 0x15ef39a5e990002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:49,046] INFO EventThread shut down for session: 0x15ef39a5e990002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:49,055] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:32:49,041] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef39a5e990002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 17:32:49,084] INFO Closed socket connection for client /127.0.0.1:63398 which had sessionid 0x15ef39a5e990002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:32:52,492] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:32:52,502] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:32:52,614] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 17:32:52,628] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:32:52,656] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:32:52,664] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:52,680] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:52,694] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,482] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,482] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,492] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,652] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,652] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:53,664] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:54,482] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:54,482] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:54,495] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:32:54,504] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,668] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,668] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,674] INFO [Transaction Coordinator 0]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:54,683] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 27000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:32:54,687] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:32:54,692] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:54,699] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:54,699] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:32:54,709] INFO [Transaction Coordinator 0]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:32:54,717] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:54,720] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,913] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,913] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:54,924] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,068] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,068] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,081] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:32:55,088] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:32:55,096] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:55,108] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:32:55,113] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,268] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,268] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,274] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,468] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,468] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,474] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,503] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,503] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:32:55,538] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:32:55,545] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:32:56,646] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:32:56,656] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:32:56,661] INFO Processed session termination for sessionid: 0x15ef39a5e990001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:32:56,671] INFO Session: 0x15ef39a5e990001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:32:56,675] INFO EventThread shut down for session: 0x15ef39a5e990001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:32:56,675] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63395 which had sessionid 0x15ef39a5e990001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:32:56,682] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:32:59,825] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2017-10-06 17:32:59,836] INFO [Kafka Server 2], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 17:32:59,869] INFO [Kafka Server 2], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 17:32:59,882] INFO [Socket Server on Broker 2], Shutting down (kafka.network.SocketServer)
[2017-10-06 17:32:59,910] INFO [Socket Server on Broker 2], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 17:32:59,918] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:59,930] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 17:32:59,943] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:59,997] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:32:59,997] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:00,016] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:00,998] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:00,998] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:01,019] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:01,999] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:01,999] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:33:02,020] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 17:33:02,028] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,108] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,108] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,134] INFO [Transaction Coordinator 2]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:33:02,144] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 25000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:33:02,156] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 17:33:02,168] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:33:02,180] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:33:02,180] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:33:02,204] INFO [Transaction Coordinator 2]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:33:02,220] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:33:02,227] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,419] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,419] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,438] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,502] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,502] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,524] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:33:02,532] INFO [Replica Manager on Broker 2]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 17:33:02,540] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:33:02,554] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:33:02,561] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,619] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,619] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,636] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,709] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,709] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,724] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,909] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,909] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:33:02,935] INFO [Replica Manager on Broker 2]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 17:33:02,944] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 17:33:02,970] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 17:33:02,989] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:33:03,000] INFO Processed session termination for sessionid: 0x15ef39a5e990000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:33:03,018] INFO Session: 0x15ef39a5e990000 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:33:03,018] INFO Closed socket connection for client /127.0.0.1:63392 which had sessionid 0x15ef39a5e990000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 17:33:03,028] INFO EventThread shut down for session: 0x15ef39a5e990000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:33:03,033] INFO [Kafka Server 2], shut down completed (kafka.server.KafkaServer)
[2017-10-06 17:42:14,599] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:42:14,610] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:42:14,614] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:42:14,618] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 17:42:14,623] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 17:42:14,656] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 17:42:14,661] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 17:42:14,680] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,687] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,693] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,698] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,703] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,709] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,891] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,909] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,920] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,924] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,931] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,936] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,943] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,948] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,957] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,976] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,979] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:14,982] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:15,016] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:42:15,224] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:42:15,231] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:42:15,238] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:42:15,242] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 17:42:26,448] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:42:26,840] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:42:26,874] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:42:26,947] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:26,962] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:42:26,962] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:26,992] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,011] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,024] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:26,817] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:42:27,218] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:42:27,225] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:42:27,037] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,281] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:42:27,297] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,281] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,306] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,316] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,320] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,324] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,328] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,336] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,335] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,345] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,353] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,361] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,370] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,378] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,394] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,452] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:27,456] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:27,493] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63474 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:42:27,492] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:27,543] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63474 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:27,573] INFO Creating new log file: log.cee (org.apache.zookeeper.server.persistence.FileTxnLog)
[2017-10-06 17:42:27,615] INFO Established session 0x15ef3a38bf90000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63474 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:27,617] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef3a38bf90000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:27,674] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:27,344] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,722] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,759] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,773] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,803] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,812] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,835] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,839] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,859] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,869] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,886] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:27,377] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.11.0-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.11.0-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2017-10-06 17:42:27,993] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:28,003] INFO Opening socket connection to server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:28,013] INFO Socket connection established to 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:28,012] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63477 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:42:28,038] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63477 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:28,072] INFO starting (kafka.server.KafkaServer)
[2017-10-06 17:42:28,081] INFO Session establishment complete on server 0:0:0:0:0:0:0:1/0:0:0:0:0:0:0:1:2181, sessionid = 0x15ef3a38bf90001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:28,093] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:28,103] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:42:28,078] INFO Established session 0x15ef3a38bf90001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63477 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:28,096] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2017-10-06 17:42:28,191] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,197] INFO Client environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,210] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,215] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,196] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 17:42:28,220] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,280] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,313] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,297] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,537] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:42:28,230] INFO Client environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,770] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,819] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:42:28,813] INFO Client environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,829] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,824] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,842] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,842] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,855] INFO Logs loading complete in 32 ms. (kafka.log.LogManager)
[2017-10-06 17:42:28,855] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:28,865] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,876] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,889] INFO Client environment:user.name=rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,893] INFO Client environment:user.home=C:\Users\rbliton (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,899] INFO Client environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,918] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4313f5bc (org.apache.zookeeper.ZooKeeper)
[2017-10-06 17:42:28,998] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:29,018] INFO Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:29,037] INFO Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:29,013] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:42:29,037] INFO Accepted socket connection from /127.0.0.1:63480 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 17:42:29,058] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:42:29,060] INFO Client attempting to establish new session at /127.0.0.1:63480 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:29,079] INFO Established session 0x15ef3a38bf90002 with negotiated timeout 6000 for client /127.0.0.1:63480 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 17:42:29,081] INFO Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x15ef3a38bf90002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 17:42:29,133] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2017-10-06 17:42:29,329] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:42:29,352] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2017-10-06 17:42:29,359] INFO Logs loading complete in 24 ms. (kafka.log.LogManager)
[2017-10-06 17:42:29,363] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:42:29,460] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,461] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,496] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:42:29,461] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,533] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:42:29,599] INFO Cluster ID = eqotAVTFRO2YZJ3Vd5jDQQ (kafka.server.KafkaServer)
[2017-10-06 17:42:29,772] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2017-10-06 17:42:29,832] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:42:29,781] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,814] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:29,797] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:29,862] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:29,782] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,781] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:29,881] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:29,918] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:29,934] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:28000,blockEndProducerId:28999) by writing to Zk with path version 29 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:42:30,006] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,008] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,007] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,086] INFO [Transaction Coordinator 2]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:30,087] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:30,087] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:30,205] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,206] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,206] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:30,129] INFO [Transaction Coordinator 2]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:30,087] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 17:42:30,358] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:30,370] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:30,390] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:42:30,479] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:30,540] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:29000,blockEndProducerId:29999) by writing to Zk with path version 30 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:42:30,829] INFO [Transaction Coordinator 1]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:30,855] INFO [Transaction Coordinator 1]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:30,878] INFO Loading logs. (kafka.log.LogManager)
[2017-10-06 17:42:30,935] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:42:31,001] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:42:30,476] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:42:31,318] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:31,332] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90001 type:create cxid:0x62 zxid:0xcf5 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:31,375] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90001 type:create cxid:0x63 zxid:0xcf6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:31,402] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:31,416] INFO Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:42:31,438] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:31,474] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:31,421] INFO Loading producer state from offset 0 for partition cluster-1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:31,492] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[2017-10-06 17:42:31,571] INFO Completed load of log cluster-1-0 with 1 log segments, log start offset 0 and log end offset 0 in 363 ms (kafka.log.Log)
[2017-10-06 17:42:31,611] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:31,694] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90000 type:create cxid:0xef zxid:0xcf8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:31,690] INFO Loading producer state from offset 0 for partition cluster-2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:31,720] INFO Completed load of log cluster-2-0 with 1 log segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2017-10-06 17:42:31,717] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90000 type:create cxid:0xf0 zxid:0xcf9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:31,759] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:31,774] INFO Registered broker 2 at path /brokers/ids/2 with addresses: EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:42:31,782] INFO Loading producer state from offset 0 for partition cluster-3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:31,795] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:31,833] INFO Completed load of log cluster-3-0 with 1 log segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2017-10-06 17:42:31,835] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:31,880] INFO Loading producer state from offset 0 for partition cluster1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:31,891] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[2017-10-06 17:42:31,902] INFO Completed load of log cluster1-0 with 1 log segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2017-10-06 17:42:31,943] INFO Loading producer state from offset 0 for partition cluster2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:31,959] INFO Completed load of log cluster2-0 with 1 log segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2017-10-06 17:42:32,016] INFO Loading producer state from offset 0 for partition cluster3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,036] INFO Completed load of log cluster3-0 with 1 log segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2017-10-06 17:42:32,082] INFO Loading producer state from offset 0 for partition clusterdb-topic1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,105] INFO Completed load of log clusterdb-topic1-0 with 1 log segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2017-10-06 17:42:32,183] INFO Loading producer state from offset 0 for partition clusterdb-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,195] INFO Completed load of log clusterdb-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2017-10-06 17:42:32,272] INFO Loading producer state from offset 0 for partition clusterdb-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,289] INFO Completed load of log clusterdb-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2017-10-06 17:42:32,343] INFO Loading producer state from offset 0 for partition clusterdb-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,402] INFO Completed load of log clusterdb-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2017-10-06 17:42:32,438] INFO Loading producer state from offset 0 for partition clusterdb-topic5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,455] INFO Completed load of log clusterdb-topic5-0 with 1 log segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2017-10-06 17:42:32,550] INFO Loading producer state from offset 0 for partition clusterdb-topic6-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,596] INFO Completed load of log clusterdb-topic6-0 with 1 log segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2017-10-06 17:42:32,662] INFO Loading producer state from offset 0 for partition clusterdb-topic7-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,657] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90000 type:delete cxid:0x1c0 zxid:0xcfb txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:32,674] INFO Completed load of log clusterdb-topic7-0 with 1 log segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2017-10-06 17:42:32,742] INFO Loading producer state from offset 0 for partition clusterdb1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:32,764] INFO Completed load of log clusterdb1-0 with 1 log segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2017-10-06 17:42:32,941] INFO Loading producer state from offset 0 for partition clusterdb2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,009] INFO Completed load of log clusterdb2-0 with 1 log segments, log start offset 0 and log end offset 0 in 163 ms (kafka.log.Log)
[2017-10-06 17:42:33,096] INFO Loading producer state from offset 0 for partition clusterdb3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,239] INFO Completed load of log clusterdb3-0 with 1 log segments, log start offset 0 and log end offset 0 in 167 ms (kafka.log.Log)
[2017-10-06 17:42:33,405] INFO Loading producer state from offset 0 for partition db-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,455] INFO Completed load of log db-0 with 1 log segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2017-10-06 17:42:33,538] INFO Loading producer state from offset 0 for partition db1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,573] INFO Completed load of log db1-0 with 1 log segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2017-10-06 17:42:33,680] INFO Loading producer state from offset 0 for partition db2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,689] INFO Completed load of log db2-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2017-10-06 17:42:33,730] INFO Loading producer state from offset 0 for partition db3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,737] INFO Completed load of log db3-0 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:33,768] INFO Loading producer state from offset 0 for partition demo-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,773] INFO Completed load of log demo-0 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:42:33,797] INFO Loading producer state from offset 0 for partition demo2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,802] INFO Completed load of log demo2-0 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:42:33,826] INFO Loading producer state from offset 0 for partition demo3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,832] INFO Completed load of log demo3-0 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:42:33,860] INFO Loading producer state from offset 0 for partition demo5-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,868] INFO Completed load of log demo5-0 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:33,893] INFO Loading producer state from offset 0 for partition filter-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,897] INFO Completed load of log filter-0 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:42:33,915] INFO Loading producer state from offset 0 for partition kafkalogger-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,919] INFO Completed load of log kafkalogger-0 with 1 log segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2017-10-06 17:42:33,942] INFO Loading producer state from offset 0 for partition kafkalogger2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,949] INFO Completed load of log kafkalogger2-0 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:42:33,969] INFO Loading producer state from offset 0 for partition test-topic-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:33,974] INFO Completed load of log test-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:42:34,002] INFO Loading producer state from offset 0 for partition test-topic2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,008] INFO Completed load of log test-topic2-0 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:34,030] INFO Loading producer state from offset 0 for partition test-topic3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,034] INFO Completed load of log test-topic3-0 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:42:34,057] INFO Loading producer state from offset 0 for partition test-topic4-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,062] INFO Completed load of log test-topic4-0 with 1 log segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2017-10-06 17:42:34,080] INFO Loading producer state from offset 0 for partition test1-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,087] INFO Completed load of log test1-0 with 1 log segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2017-10-06 17:42:34,112] INFO Loading producer state from offset 0 for partition test2-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,116] INFO Completed load of log test2-0 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:42:34,134] INFO Loading producer state from offset 0 for partition test3-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,138] INFO Completed load of log test3-0 with 1 log segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2017-10-06 17:42:34,157] INFO Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,161] INFO Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2017-10-06 17:42:34,180] INFO Loading producer state from offset 0 for partition __consumer_offsets-1 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,185] INFO Completed load of log __consumer_offsets-1 with 1 log segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2017-10-06 17:42:34,204] INFO Loading producer state from offset 0 for partition __consumer_offsets-10 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,209] INFO Completed load of log __consumer_offsets-10 with 1 log segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2017-10-06 17:42:34,226] INFO Loading producer state from offset 0 for partition __consumer_offsets-11 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,230] INFO Completed load of log __consumer_offsets-11 with 1 log segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2017-10-06 17:42:34,248] INFO Loading producer state from offset 0 for partition __consumer_offsets-12 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,252] INFO Completed load of log __consumer_offsets-12 with 1 log segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2017-10-06 17:42:34,272] INFO Loading producer state from offset 0 for partition __consumer_offsets-13 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,278] INFO Completed load of log __consumer_offsets-13 with 1 log segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2017-10-06 17:42:34,299] INFO Loading producer state from offset 0 for partition __consumer_offsets-14 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,309] INFO Completed load of log __consumer_offsets-14 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:34,333] INFO Loading producer state from offset 0 for partition __consumer_offsets-15 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,338] INFO Completed load of log __consumer_offsets-15 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:42:34,367] INFO Loading producer state from offset 0 for partition __consumer_offsets-16 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,373] INFO Completed load of log __consumer_offsets-16 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:42:34,400] INFO Loading producer state from offset 0 for partition __consumer_offsets-17 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,409] INFO Completed load of log __consumer_offsets-17 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:42:34,433] INFO Loading producer state from offset 0 for partition __consumer_offsets-18 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,440] INFO Completed load of log __consumer_offsets-18 with 1 log segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2017-10-06 17:42:34,468] INFO Loading producer state from offset 0 for partition __consumer_offsets-19 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,473] INFO Completed load of log __consumer_offsets-19 with 1 log segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2017-10-06 17:42:34,495] INFO Loading producer state from offset 0 for partition __consumer_offsets-2 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,501] INFO Completed load of log __consumer_offsets-2 with 1 log segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2017-10-06 17:42:34,538] INFO Loading producer state from offset 0 for partition __consumer_offsets-20 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,553] INFO Completed load of log __consumer_offsets-20 with 1 log segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2017-10-06 17:42:34,592] INFO Loading producer state from offset 0 for partition __consumer_offsets-21 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,608] INFO Completed load of log __consumer_offsets-21 with 1 log segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2017-10-06 17:42:34,640] INFO Loading producer state from offset 0 for partition __consumer_offsets-22 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,652] INFO Completed load of log __consumer_offsets-22 with 1 log segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2017-10-06 17:42:34,697] INFO Loading producer state from offset 0 for partition __consumer_offsets-23 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,709] INFO Completed load of log __consumer_offsets-23 with 1 log segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2017-10-06 17:42:34,741] INFO Loading producer state from offset 0 for partition __consumer_offsets-24 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,750] INFO Completed load of log __consumer_offsets-24 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:34,785] INFO Loading producer state from offset 0 for partition __consumer_offsets-25 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,794] INFO Completed load of log __consumer_offsets-25 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:42:34,823] INFO Loading producer state from offset 0 for partition __consumer_offsets-26 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,832] INFO Completed load of log __consumer_offsets-26 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:34,865] INFO Loading producer state from offset 0 for partition __consumer_offsets-27 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,874] INFO Completed load of log __consumer_offsets-27 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:34,905] INFO Loading producer state from offset 0 for partition __consumer_offsets-28 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,915] INFO Completed load of log __consumer_offsets-28 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:42:34,953] INFO Loading producer state from offset 0 for partition __consumer_offsets-29 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:34,961] INFO Completed load of log __consumer_offsets-29 with 1 log segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2017-10-06 17:42:34,992] INFO Loading producer state from offset 0 for partition __consumer_offsets-3 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,000] INFO Completed load of log __consumer_offsets-3 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:35,032] INFO Loading producer state from offset 0 for partition __consumer_offsets-30 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,040] INFO Completed load of log __consumer_offsets-30 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:35,072] INFO Loading producer state from offset 0 for partition __consumer_offsets-31 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,079] INFO Completed load of log __consumer_offsets-31 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:35,108] INFO Loading producer state from offset 0 for partition __consumer_offsets-32 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,116] INFO Completed load of log __consumer_offsets-32 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,147] INFO Loading producer state from offset 0 for partition __consumer_offsets-33 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,154] INFO Completed load of log __consumer_offsets-33 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:42:35,182] INFO Loading producer state from offset 0 for partition __consumer_offsets-34 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,191] INFO Completed load of log __consumer_offsets-34 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,221] INFO Loading producer state from offset 0 for partition __consumer_offsets-35 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,231] INFO Completed load of log __consumer_offsets-35 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:35,262] INFO Loading producer state from offset 0 for partition __consumer_offsets-36 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,270] INFO Completed load of log __consumer_offsets-36 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:42:35,300] INFO Loading producer state from offset 0 for partition __consumer_offsets-37 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,308] INFO Completed load of log __consumer_offsets-37 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:35,339] INFO Loading producer state from offset 0 for partition __consumer_offsets-38 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,347] INFO Completed load of log __consumer_offsets-38 with 1 log segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2017-10-06 17:42:35,374] INFO Loading producer state from offset 0 for partition __consumer_offsets-39 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,382] INFO Completed load of log __consumer_offsets-39 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,408] INFO Loading producer state from offset 0 for partition __consumer_offsets-4 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,416] INFO Completed load of log __consumer_offsets-4 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,442] INFO Loading producer state from offset 0 for partition __consumer_offsets-40 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,451] INFO Completed load of log __consumer_offsets-40 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,481] INFO Loading producer state from offset 0 for partition __consumer_offsets-41 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,490] INFO Completed load of log __consumer_offsets-41 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:35,518] INFO Loading producer state from offset 0 for partition __consumer_offsets-42 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,527] INFO Completed load of log __consumer_offsets-42 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,556] INFO Loading producer state from offset 0 for partition __consumer_offsets-43 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,564] INFO Completed load of log __consumer_offsets-43 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:35,593] INFO Loading producer state from offset 0 for partition __consumer_offsets-44 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,600] INFO Completed load of log __consumer_offsets-44 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,629] INFO Loading producer state from offset 0 for partition __consumer_offsets-45 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,637] INFO Completed load of log __consumer_offsets-45 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,663] INFO Loading producer state from offset 0 for partition __consumer_offsets-46 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,671] INFO Completed load of log __consumer_offsets-46 with 1 log segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2017-10-06 17:42:35,698] INFO Loading producer state from offset 0 for partition __consumer_offsets-47 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,708] INFO Completed load of log __consumer_offsets-47 with 1 log segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2017-10-06 17:42:35,735] INFO Loading producer state from offset 0 for partition __consumer_offsets-48 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,743] INFO Completed load of log __consumer_offsets-48 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,776] INFO Loading producer state from offset 0 for partition __consumer_offsets-49 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,783] INFO Completed load of log __consumer_offsets-49 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,811] INFO Loading producer state from offset 0 for partition __consumer_offsets-5 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,819] INFO Completed load of log __consumer_offsets-5 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,847] INFO Loading producer state from offset 0 for partition __consumer_offsets-6 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,855] INFO Completed load of log __consumer_offsets-6 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,882] INFO Loading producer state from offset 0 for partition __consumer_offsets-7 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,891] INFO Completed load of log __consumer_offsets-7 with 1 log segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2017-10-06 17:42:35,922] INFO Loading producer state from offset 0 for partition __consumer_offsets-8 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,930] INFO Completed load of log __consumer_offsets-8 with 1 log segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2017-10-06 17:42:35,959] INFO Loading producer state from offset 0 for partition __consumer_offsets-9 with message format version 2 (kafka.log.Log)
[2017-10-06 17:42:35,970] INFO Completed load of log __consumer_offsets-9 with 1 log segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2017-10-06 17:42:35,985] INFO Logs loading complete in 5093 ms. (kafka.log.LogManager)
[2017-10-06 17:42:36,088] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2017-10-06 17:42:36,095] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2017-10-06 17:42:36,190] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2017-10-06 17:42:36,199] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2017-10-06 17:42:36,233] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,243] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,243] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,355] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,356] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,365] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 17:42:36,446] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:36,459] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:42:36,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:36,504] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:30000,blockEndProducerId:30999) by writing to Zk with path version 31 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 17:42:36,589] INFO [Transaction Coordinator 0]: Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:36,601] INFO [Transaction Coordinator 0]: Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 17:42:36,629] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 17:42:36,679] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2017-10-06 17:42:36,942] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:36,952] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90002 type:create cxid:0x62 zxid:0xcfd txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:36,963] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90002 type:create cxid:0x63 zxid:0xcfe txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 17:42:36,989] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 17:42:36,996] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-10-06 17:42:37,020] INFO Kafka version : 0.11.0.1 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:37,074] INFO Kafka commitId : c2a0d5f9b1f45bf5 (org.apache.kafka.common.utils.AppInfoParser)
[2017-10-06 17:42:37,186] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2017-10-06 17:42:38,252] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,317] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,362] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,398] INFO Replica loaded for partition cluster-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,413] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,431] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,452] INFO Replica loaded for partition cluster2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,468] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,480] INFO Replica loaded for partition demo3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,498] INFO Replica loaded for partition test1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,651] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,674] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,689] INFO Replica loaded for partition db-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,705] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,720] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,734] INFO Replica loaded for partition clusterdb-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,744] INFO Replica loaded for partition clusterdb1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,756] INFO Replica loaded for partition kafkalogger2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,772] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,787] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,800] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,815] INFO Replica loaded for partition clusterdb-topic5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,839] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,852] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,870] INFO Replica loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,887] INFO Replica loaded for partition demo2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,924] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,935] INFO Replica loaded for partition test-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,943] INFO Replica loaded for partition demo5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,953] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,961] INFO Replica loaded for partition db1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,973] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,983] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:38,995] INFO Replica loaded for partition cluster-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,008] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,019] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,029] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,040] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,051] INFO Replica loaded for partition clusterdb-topic7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,061] INFO Replica loaded for partition cluster1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,070] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,080] INFO Replica loaded for partition clusterdb3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,092] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,106] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,116] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,126] INFO Replica loaded for partition clusterdb-topic1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,134] INFO Replica loaded for partition clusterdb-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,144] INFO Replica loaded for partition demo-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,155] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,166] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,175] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,188] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,197] INFO Replica loaded for partition kafkalogger-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,209] INFO Replica loaded for partition cluster-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,220] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,233] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,240] INFO Replica loaded for partition test2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,253] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,261] INFO Replica loaded for partition test-topic2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,272] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,280] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,292] INFO Replica loaded for partition filter-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,301] INFO Replica loaded for partition clusterdb-topic3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,314] INFO Replica loaded for partition db3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,323] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,336] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,351] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,362] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,373] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,387] INFO Replica loaded for partition clusterdb2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,395] INFO Replica loaded for partition clusterdb-topic6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,407] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,416] INFO Replica loaded for partition cluster3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,429] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,440] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,453] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,464] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,475] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,485] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,496] INFO Replica loaded for partition db2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,508] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,517] INFO Replica loaded for partition test-topic4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,528] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,537] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2017-10-06 17:42:39,544] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:42:39,561] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:42:39,633] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,db1-0,__consumer_offsets-30,clusterdb-topic2-0,cluster-3-0,__consumer_offsets-8,__consumer_offsets-21,clusterdb-topic1-0,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,cluster1-0,cluster-2-0,filter-0,clusterdb2-0,__consumer_offsets-25,__consumer_offsets-35,test3-0,demo2-0,__consumer_offsets-41,__consumer_offsets-33,clusterdb-topic5-0,__consumer_offsets-23,__consumer_offsets-49,test-topic3-0,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,demo5-0,__consumer_offsets-31,clusterdb-topic6-0,__consumer_offsets-36,__consumer_offsets-42,cluster-1-0,__consumer_offsets-3,__consumer_offsets-18,clusterdb1-0,test1-0,cluster3-0,__consumer_offsets-37,demo-0,clusterdb-topic7-0,__consumer_offsets-15,__consumer_offsets-24,db2-0,db-0,clusterdb-topic4-0,demo3-0,test-topic2-0,__consumer_offsets-38,clusterdb3-0,__consumer_offsets-17,__consumer_offsets-48,kafkalogger-0,__consumer_offsets-19,__consumer_offsets-11,cluster2-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,db3-0,test-topic-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,clusterdb-topic3-0,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,test-topic4-0,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,test2-0,__consumer_offsets-32,kafkalogger2-0,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
[2017-10-06 17:42:39,712] INFO Partition [__consumer_offsets,0] on broker 0: __consumer_offsets-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,732] INFO Partition [__consumer_offsets,29] on broker 0: __consumer_offsets-29 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,742] INFO Partition [__consumer_offsets,48] on broker 0: __consumer_offsets-48 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,753] INFO Partition [cluster-2,0] on broker 0: cluster-2-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,762] INFO Partition [__consumer_offsets,10] on broker 0: __consumer_offsets-10 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,774] INFO Partition [__consumer_offsets,45] on broker 0: __consumer_offsets-45 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,781] INFO Partition [cluster2,0] on broker 0: cluster2-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,790] INFO Partition [__consumer_offsets,26] on broker 0: __consumer_offsets-26 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,798] INFO Partition [demo3,0] on broker 0: demo3-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,807] INFO Partition [test1,0] on broker 0: test1-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,818] INFO Partition [__consumer_offsets,7] on broker 0: __consumer_offsets-7 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,829] INFO Partition [__consumer_offsets,42] on broker 0: __consumer_offsets-42 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,839] INFO Partition [db,0] on broker 0: db-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,846] INFO Partition [__consumer_offsets,4] on broker 0: __consumer_offsets-4 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,859] INFO Partition [__consumer_offsets,23] on broker 0: __consumer_offsets-23 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,869] INFO Partition [clusterdb-topic2,0] on broker 0: clusterdb-topic2-0 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,879] INFO Partition [clusterdb1,0] on broker 0: clusterdb1-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,888] INFO Partition [kafkalogger2,0] on broker 0: kafkalogger2-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,898] INFO Partition [__consumer_offsets,1] on broker 0: __consumer_offsets-1 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,904] INFO Partition [__consumer_offsets,20] on broker 0: __consumer_offsets-20 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,920] INFO Partition [__consumer_offsets,39] on broker 0: __consumer_offsets-39 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,928] INFO Partition [clusterdb-topic5,0] on broker 0: clusterdb-topic5-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,936] INFO Partition [__consumer_offsets,17] on broker 0: __consumer_offsets-17 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,942] INFO Partition [__consumer_offsets,36] on broker 0: __consumer_offsets-36 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,951] INFO Partition [test-topic,0] on broker 0: test-topic-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,958] INFO Partition [demo2,0] on broker 0: demo2-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,969] INFO Partition [__consumer_offsets,14] on broker 0: __consumer_offsets-14 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,975] INFO Partition [test-topic3,0] on broker 0: test-topic3-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,983] INFO Partition [demo5,0] on broker 0: demo5-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,990] INFO Partition [test3,0] on broker 0: test3-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:39,995] INFO Partition [db1,0] on broker 0: db1-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,002] INFO Partition [__consumer_offsets,33] on broker 0: __consumer_offsets-33 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,012] INFO Partition [__consumer_offsets,49] on broker 0: __consumer_offsets-49 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,018] INFO Partition [cluster-1,0] on broker 0: cluster-1-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,027] INFO Partition [__consumer_offsets,11] on broker 0: __consumer_offsets-11 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,034] INFO Partition [__consumer_offsets,30] on broker 0: __consumer_offsets-30 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,044] INFO Partition [__consumer_offsets,46] on broker 0: __consumer_offsets-46 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,053] INFO Partition [__consumer_offsets,27] on broker 0: __consumer_offsets-27 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,066] INFO Partition [clusterdb-topic7,0] on broker 0: clusterdb-topic7-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,074] INFO Partition [cluster1,0] on broker 0: cluster1-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,080] INFO Partition [__consumer_offsets,8] on broker 0: __consumer_offsets-8 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,088] INFO Partition [clusterdb3,0] on broker 0: clusterdb3-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,095] INFO Partition [__consumer_offsets,24] on broker 0: __consumer_offsets-24 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,101] INFO Partition [__consumer_offsets,43] on broker 0: __consumer_offsets-43 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,110] INFO Partition [__consumer_offsets,5] on broker 0: __consumer_offsets-5 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,116] INFO Partition [clusterdb-topic1,0] on broker 0: clusterdb-topic1-0 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,125] INFO Partition [clusterdb-topic4,0] on broker 0: clusterdb-topic4-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,133] INFO Partition [demo,0] on broker 0: demo-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,139] INFO Partition [__consumer_offsets,21] on broker 0: __consumer_offsets-21 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,147] INFO Partition [__consumer_offsets,40] on broker 0: __consumer_offsets-40 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,157] INFO Partition [__consumer_offsets,2] on broker 0: __consumer_offsets-2 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,165] INFO Partition [__consumer_offsets,37] on broker 0: __consumer_offsets-37 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,178] INFO Partition [kafkalogger,0] on broker 0: kafkalogger-0 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,184] INFO Partition [cluster-3,0] on broker 0: cluster-3-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,196] INFO Partition [__consumer_offsets,18] on broker 0: __consumer_offsets-18 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,202] INFO Partition [__consumer_offsets,15] on broker 0: __consumer_offsets-15 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,212] INFO Partition [test2,0] on broker 0: test2-0 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,219] INFO Partition [__consumer_offsets,34] on broker 0: __consumer_offsets-34 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,228] INFO Partition [test-topic2,0] on broker 0: test-topic2-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,234] INFO Partition [__consumer_offsets,12] on broker 0: __consumer_offsets-12 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,242] INFO Partition [__consumer_offsets,31] on broker 0: __consumer_offsets-31 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,249] INFO Partition [filter,0] on broker 0: filter-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,256] INFO Partition [clusterdb-topic3,0] on broker 0: clusterdb-topic3-0 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,262] INFO Partition [db3,0] on broker 0: db3-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,271] INFO Partition [__consumer_offsets,9] on broker 0: __consumer_offsets-9 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,278] INFO Partition [__consumer_offsets,47] on broker 0: __consumer_offsets-47 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,286] INFO Partition [__consumer_offsets,19] on broker 0: __consumer_offsets-19 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,293] INFO Partition [__consumer_offsets,28] on broker 0: __consumer_offsets-28 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,300] INFO Partition [__consumer_offsets,38] on broker 0: __consumer_offsets-38 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,308] INFO Partition [clusterdb2,0] on broker 0: clusterdb2-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,315] INFO Partition [clusterdb-topic6,0] on broker 0: clusterdb-topic6-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,321] INFO Partition [__consumer_offsets,35] on broker 0: __consumer_offsets-35 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,330] INFO Partition [cluster3,0] on broker 0: cluster3-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,336] INFO Partition [__consumer_offsets,44] on broker 0: __consumer_offsets-44 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,350] INFO Partition [__consumer_offsets,6] on broker 0: __consumer_offsets-6 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,356] INFO Partition [__consumer_offsets,25] on broker 0: __consumer_offsets-25 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,365] INFO Partition [__consumer_offsets,16] on broker 0: __consumer_offsets-16 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,373] INFO Partition [__consumer_offsets,22] on broker 0: __consumer_offsets-22 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,381] INFO Partition [__consumer_offsets,41] on broker 0: __consumer_offsets-41 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,388] INFO Partition [db2,0] on broker 0: db2-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,395] INFO Partition [__consumer_offsets,32] on broker 0: __consumer_offsets-32 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,401] INFO Partition [test-topic4,0] on broker 0: test-topic4-0 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,409] INFO Partition [__consumer_offsets,3] on broker 0: __consumer_offsets-3 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,416] INFO Partition [__consumer_offsets,13] on broker 0: __consumer_offsets-13 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2017-10-06 17:42:40,439] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,449] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,455] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,461] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,471] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,476] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-25 in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,477] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,488] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,493] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,502] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,509] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,516] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,521] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,535] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,540] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,550] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,555] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,564] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,571] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,579] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,587] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,598] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,604] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,611] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,619] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,627] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,638] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,645] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,658] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,664] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,677] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,684] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,698] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,704] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,718] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,727] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,738] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,744] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,759] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,765] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,778] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,788] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,797] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,803] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,810] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,818] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,827] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,834] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,841] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,849] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,855] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,862] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,870] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,877] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,886] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,893] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,900] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,908] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,915] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,922] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,929] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,937] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,945] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,953] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,960] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,968] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,975] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,983] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,991] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:40,998] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,008] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,014] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,026] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,034] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,042] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,050] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,057] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,064] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,076] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,081] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,088] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,094] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,100] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,108] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,113] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,118] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,124] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,133] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,139] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,146] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,156] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,160] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,167] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,173] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,179] INFO [Group Metadata Manager on Broker 0]: Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,185] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,207] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,218] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,224] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:42:41,237] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:43:17,801] INFO [GroupCoordinator 0]: Preparing to rebalance group test1 with old generation 0 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:43:17,870] INFO [GroupCoordinator 0]: Stabilized group test1 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:43:17,944] INFO [GroupCoordinator 0]: Preparing to rebalance group test1 with old generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:43:17,984] INFO [GroupCoordinator 0]: Stabilized group test1 generation 2 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:43:18,082] INFO [GroupCoordinator 0]: Assignment received from leader for group test1 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:43:18,146] INFO Updated PartitionLeaderEpoch. New: {epoch:15, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-37. Cache now contains 0 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2017-10-06 17:45:02,457] INFO Updated PartitionLeaderEpoch. New: {epoch:9, offset:0}, Current: {epoch:-1, offset-1} for Partition: test3-0. Cache now contains 0 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2017-10-06 17:45:02,505] INFO Updated PartitionLeaderEpoch. New: {epoch:9, offset:0}, Current: {epoch:-1, offset-1} for Partition: test2-0. Cache now contains 0 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2017-10-06 17:45:02,556] INFO Updated PartitionLeaderEpoch. New: {epoch:9, offset:0}, Current: {epoch:-1, offset-1} for Partition: test1-0. Cache now contains 0 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2017-10-06 17:48:18,140] INFO [GroupCoordinator 0]: Preparing to rebalance group test1 with old generation 2 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:48:18,265] INFO [GroupCoordinator 0]: Stabilized group test1 generation 3 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:48:18,335] INFO [GroupCoordinator 0]: Assignment received from leader for group test1 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:52:18,054] INFO [GroupCoordinator 0]: Preparing to rebalance group test1 with old generation 3 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:52:18,488] INFO [GroupCoordinator 0]: Stabilized group test1 generation 4 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:52:18,505] INFO [GroupCoordinator 0]: Assignment received from leader for group test1 for generation 4 (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 17:52:29,863] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:52:30,372] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 17:52:36,467] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2017-10-06 18:00:10,318] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2017-10-06 18:00:10,351] INFO [Kafka Server 2], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 18:00:10,474] INFO [Kafka Server 2], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 18:00:10,490] INFO [Socket Server on Broker 2], Shutting down (kafka.network.SocketServer)
[2017-10-06 18:00:10,516] INFO [Socket Server on Broker 2], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 18:00:10,534] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:10,550] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:10,566] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:10,811] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:10,811] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:10,818] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,326] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,326] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,331] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,814] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,814] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:11,826] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 18:00:11,831] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:11,855] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:11,855] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:11,869] INFO [Transaction Coordinator 2]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:11,876] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 28000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 18:00:11,885] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 18:00:11,890] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:11,897] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:11,897] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:11,914] INFO [Transaction Coordinator 2]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:11,920] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:11,927] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,045] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,045] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,049] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,246] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,246] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,251] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:12,265] INFO [Replica Manager on Broker 2]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 18:00:12,272] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:12,281] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:12,286] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,446] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,446] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,455] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,653] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,653] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,664] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,846] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,846] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:12,857] INFO [Replica Manager on Broker 2]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 18:00:12,865] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 18:00:12,898] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 18:00:12,924] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 18:00:12,933] INFO Processed session termination for sessionid: 0x15ef3a38bf90000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:12,977] INFO Session: 0x15ef3a38bf90000 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 18:00:12,987] INFO EventThread shut down for session: 0x15ef3a38bf90000 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 18:00:12,991] INFO [Kafka Server 2], shut down completed (kafka.server.KafkaServer)
[2017-10-06 18:00:12,999] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client sessionid 0x15ef3a38bf90000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:748)
[2017-10-06 18:00:13,057] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63474 which had sessionid 0x15ef3a38bf90000 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 18:00:13,084] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:13,088] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:13,133] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:13,133] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90001 type:create cxid:0x69 zxid:0xd56 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:13,237] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:14,552] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90002 type:delete cxid:0x16e zxid:0xd58 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:17,729] INFO [GroupCoordinator 0]: Member consumer-1-826444eb-9e2e-4228-b0e9-92c3ddf8d1aa in group test1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:17,741] INFO [GroupCoordinator 0]: Preparing to rebalance group test1 with old generation 4 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:24,032] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2017-10-06 18:00:24,040] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 18:00:24,115] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 18:00:24,128] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2017-10-06 18:00:24,151] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 18:00:24,173] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:24,186] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:24,198] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:24,493] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:24,493] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:24,509] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:24,565] INFO [GroupCoordinator 0]: Member consumer-1-42c0a37e-cc4a-47d5-89f6-c86e56396e66 in group test1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:25,494] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:25,494] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:25,505] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:26,495] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:26,495] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:26,513] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 18:00:26,522] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,539] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,539] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,562] INFO [Transaction Coordinator 0]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:26,571] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 30000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 18:00:26,578] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 18:00:26,587] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:26,596] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:26,596] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:26,615] INFO [Transaction Coordinator 0]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:26,626] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:26,633] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,767] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,767] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,780] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,970] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,970] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:26,985] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:26,992] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 18:00:26,997] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:27,008] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:27,013] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,139] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,139] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,154] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,340] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,340] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,351] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,540] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,540] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:27,565] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 18:00:27,578] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 18:00:28,841] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 18:00:28,857] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 18:00:28,865] INFO Processed session termination for sessionid: 0x15ef3a38bf90002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:28,879] INFO Session: 0x15ef3a38bf90002 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 18:00:28,890] INFO EventThread shut down for session: 0x15ef3a38bf90002 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 18:00:28,895] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2017-10-06 18:00:28,883] INFO Closed socket connection for client /127.0.0.1:63480 which had sessionid 0x15ef3a38bf90002 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 18:00:28,917] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:28,937] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-10-06 18:00:30,713] INFO Got user-level KeeperException when processing sessionid:0x15ef3a38bf90001 type:delete cxid:0x1ca zxid:0xd5c txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:49,022] INFO [Kafka Server 1], shutting down (kafka.server.KafkaServer)
[2017-10-06 18:00:49,030] INFO [Kafka Server 1], Starting controlled shutdown (kafka.server.KafkaServer)
[2017-10-06 18:00:49,085] INFO [Kafka Server 1], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2017-10-06 18:00:49,096] INFO [Socket Server on Broker 1], Shutting down (kafka.network.SocketServer)
[2017-10-06 18:00:49,122] INFO [Socket Server on Broker 1], Shutdown completed (kafka.network.SocketServer)
[2017-10-06 18:00:49,127] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:49,141] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2017-10-06 18:00:49,152] INFO [ThrottledRequestReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:49,850] INFO [ThrottledRequestReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:49,851] INFO [ThrottledRequestReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:49,858] INFO [ThrottledRequestReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:50,850] INFO [ThrottledRequestReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:50,850] INFO [ThrottledRequestReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:50,859] INFO [ThrottledRequestReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:51,849] INFO [ThrottledRequestReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:51,849] INFO [ThrottledRequestReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[2017-10-06 18:00:51,860] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2017-10-06 18:00:51,881] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,051] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,051] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,073] INFO [Transaction Coordinator 1]: Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:52,084] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 29000 (kafka.coordinator.transaction.ProducerIdManager)
[2017-10-06 18:00:52,092] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2017-10-06 18:00:52,101] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:52,110] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:52,110] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2017-10-06 18:00:52,129] INFO [Transaction Coordinator 1]: Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-06 18:00:52,141] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:52,147] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,252] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,252] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,260] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,451] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,451] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,468] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2017-10-06 18:00:52,477] INFO [Replica Manager on Broker 1]: Shutting down (kafka.server.ReplicaManager)
[2017-10-06 18:00:52,485] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:52,495] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2017-10-06 18:00:52,503] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,652] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,652] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,671] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,852] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,852] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:52,860] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:53,054] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:53,054] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2017-10-06 18:00:53,069] INFO [Replica Manager on Broker 1]: Shut down completely (kafka.server.ReplicaManager)
[2017-10-06 18:00:53,081] INFO Shutting down. (kafka.log.LogManager)
[2017-10-06 18:00:53,128] INFO Shutdown complete. (kafka.log.LogManager)
[2017-10-06 18:00:53,159] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2017-10-06 18:00:53,168] INFO Processed session termination for sessionid: 0x15ef3a38bf90001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2017-10-06 18:00:53,187] INFO Session: 0x15ef3a38bf90001 closed (org.apache.zookeeper.ZooKeeper)
[2017-10-06 18:00:53,202] INFO EventThread shut down for session: 0x15ef3a38bf90001 (org.apache.zookeeper.ClientCnxn)
[2017-10-06 18:00:53,204] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer)
[2017-10-06 18:00:53,187] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63477 which had sessionid 0x15ef3a38bf90001 (org.apache.zookeeper.server.NIOServerCnxn)
[2017-10-06 18:01:41,953] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 18:01:41,965] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:41,969] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:41,973] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:41,976] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 18:01:42,007] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 18:01:42,014] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 18:01:42,035] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,044] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,049] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,054] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,059] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,063] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,253] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,271] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,281] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,286] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,294] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,298] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,304] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,310] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,320] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,340] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,344] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,349] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:42,381] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 18:01:42,387] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:117)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:87)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:53)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:116)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)
[2017-10-06 18:01:55,176] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 18:01:55,188] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:55,193] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:55,199] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2017-10-06 18:01:55,205] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2017-10-06 18:01:55,242] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2017-10-06 18:01:55,249] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2017-10-06 18:01:55,271] INFO Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,279] INFO Server environment:host.name=LNAR-PC0611K6.corp.capgemini.com (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,285] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,290] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,296] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_131\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,303] INFO Server environment:java.class.path=C:\workspace\kafka-demo\libs\aopalliance-repackaged-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\argparse4j-0.7.0.jar;C:\workspace\kafka-demo\libs\commons-lang3-3.5.jar;C:\workspace\kafka-demo\libs\connect-api-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-file-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-json-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-runtime-0.11.0.1.jar;C:\workspace\kafka-demo\libs\connect-transforms-0.11.0.1.jar;C:\workspace\kafka-demo\libs\guava-20.0.jar;C:\workspace\kafka-demo\libs\hk2-api-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-locator-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\hk2-utils-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\jackson-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-core-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-databind-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-base-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-jaxrs-json-provider-2.8.5.jar;C:\workspace\kafka-demo\libs\jackson-module-jaxb-annotations-2.8.5.jar;C:\workspace\kafka-demo\libs\javassist-3.21.0-GA.jar;C:\workspace\kafka-demo\libs\javax.annotation-api-1.2.jar;C:\workspace\kafka-demo\libs\javax.inject-1.jar;C:\workspace\kafka-demo\libs\javax.inject-2.5.0-b05.jar;C:\workspace\kafka-demo\libs\javax.servlet-api-3.1.0.jar;C:\workspace\kafka-demo\libs\javax.ws.rs-api-2.0.1.jar;C:\workspace\kafka-demo\libs\jersey-client-2.24.jar;C:\workspace\kafka-demo\libs\jersey-common-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-2.24.jar;C:\workspace\kafka-demo\libs\jersey-container-servlet-core-2.24.jar;C:\workspace\kafka-demo\libs\jersey-guava-2.24.jar;C:\workspace\kafka-demo\libs\jersey-media-jaxb-2.24.jar;C:\workspace\kafka-demo\libs\jersey-server-2.24.jar;C:\workspace\kafka-demo\libs\jetty-continuation-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-http-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-io-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-security-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-server-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlet-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-servlets-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jetty-util-9.2.15.v20160210.jar;C:\workspace\kafka-demo\libs\jopt-simple-5.0.3.jar;C:\workspace\kafka-demo\libs\kafka-clients-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-log4j-appender-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-streams-examples-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka-tools-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-javadoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-scaladoc.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test-sources.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1-test.jar.asc;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar;C:\workspace\kafka-demo\libs\kafka_2.12-0.11.0.1.jar.asc;C:\workspace\kafka-demo\libs\log4j-1.2.17.jar;C:\workspace\kafka-demo\libs\lz4-1.3.0.jar;C:\workspace\kafka-demo\libs\maven-artifact-3.5.0.jar;C:\workspace\kafka-demo\libs\metrics-core-2.2.0.jar;C:\workspace\kafka-demo\libs\osgi-resource-locator-1.0.1.jar;C:\workspace\kafka-demo\libs\plexus-utils-3.0.24.jar;C:\workspace\kafka-demo\libs\reflections-0.9.11.jar;C:\workspace\kafka-demo\libs\rocksdbjni-5.0.1.jar;C:\workspace\kafka-demo\libs\scala-library-2.12.2.jar;C:\workspace\kafka-demo\libs\scala-parser-combinators_2.12-1.0.4.jar;C:\workspace\kafka-demo\libs\slf4j-api-1.7.25.jar;C:\workspace\kafka-demo\libs\slf4j-log4j12-1.7.25.jar;C:\workspace\kafka-demo\libs\snappy-java-1.1.2.6.jar;C:\workspace\kafka-demo\libs\validation-api-1.1.0.Final.jar;C:\workspace\kafka-demo\libs\zkclient-0.10.jar;C:\workspace\kafka-demo\libs\zookeeper-3.4.10.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,539] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_131\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\ProgramData\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\apache-maven-3.5.0\bin;C:\Users\rbliton\AppData\Local\GitHubDesktop\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,568] INFO Server environment:java.io.tmpdir=C:\Users\rbliton\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,582] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,589] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,597] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,603] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,615] INFO Server environment:user.name=rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,620] INFO Server environment:user.home=C:\Users\rbliton (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,629] INFO Server environment:user.dir=C:\workspace\kafka-demo\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,650] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,654] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,658] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2017-10-06 18:01:55,694] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2017-10-06 18:01:55,948] ERROR 2435(higestZxid) > 2429(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 18:01:55,959] ERROR 2435(higestZxid) > 2430(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 18:01:55,967] ERROR 2435(higestZxid) > 2431(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2017-10-06 18:01:55,976] ERROR 2435(higestZxid) > 2432(next log) for type -11 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
